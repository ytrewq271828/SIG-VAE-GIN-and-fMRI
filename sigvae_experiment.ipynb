{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "torch.Size([2708, 1433])\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0526, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import dgl.data\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sigvaemodel import SIGVAE_GIN\n",
    "from loss import loss\n",
    "import time\n",
    "\n",
    "CoraDataset=dgl.data.CoraGraphDataset()\n",
    "graph=CoraDataset[0]\n",
    "featureMatrix=graph.ndata['feat']\n",
    "print(featureMatrix.size())\n",
    "print(featureMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edges_to_lists(headMatrix, tailMatrix):\n",
    "    results=[]\n",
    "    assert len(headMatrix)==len(tailMatrix)\n",
    "    hlength=len(headMatrix)\n",
    "    for i in range(hlength):\n",
    "        results.append([headMatrix[i], tailMatrix[i]])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(graph):\n",
    "    u, v=graph.edges()\n",
    "    testidx=np.arange(graph.number_of_edges())\n",
    "    testidx=np.random.permutation(testidx)\n",
    "    testSize=int(len(testidx)/10)\n",
    "    train_size=graph.number_of_edges()-testSize\n",
    "    test_pos_u, test_pos_v=u[testidx[:testSize]], v[testidx[:testSize]]\n",
    "    train_pos_u, train_pos_v = u[testidx[testSize:]], v[testidx[testSize:]]\n",
    "\n",
    "    adj=sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
    "    adj_neg=1-adj.todense()-np.eye(graph.number_of_nodes())\n",
    "    adj=adj.todense()\n",
    "    neg_u, neg_v=np.where(adj_neg!=0)\n",
    "    #print(len(neg_u))\n",
    "    #print(len(neg_v))\n",
    "    neg_testidx=np.random.choice(len(neg_u), graph.number_of_edges())\n",
    "    test_neg_u, test_neg_v=neg_u[neg_testidx[:testSize]], neg_v[neg_testidx[:testSize]]\n",
    "    train_neg_u, train_neg_v=neg_u[neg_testidx[testSize:]], neg_v[neg_testidx[testSize:]]\n",
    "    #print(test_neg_u)\n",
    "    #print(test_neg_v)\n",
    "    adj_train=sp.coo_matrix((np.ones(len(train_pos_u)), (train_pos_u.numpy(), train_pos_v.numpy())))\n",
    "    adj_train=adj_train-sp.dia_matrix((adj_train.diagonal()[np.newaxis, :], [0]), shape=adj_train.shape)\n",
    "    adj_train=adj_train.todense()\n",
    "    adj_test=sp.coo_matrix((np.ones(len(test_pos_u)), (test_pos_u.numpy(), test_pos_v.numpy())))\n",
    "    adj_test=adj_test-sp.dia_matrix((adj_test.diagonal()[np.newaxis, :], [0]), shape=adj_test.shape)\n",
    "    adj_test=adj_test.todense()\n",
    "    train_graph=dgl.remove_edges(graph, testidx[:testSize])\n",
    "    train_pos=edges_to_lists(train_pos_u, train_pos_v)\n",
    "    test_pos=edges_to_lists(test_pos_u, test_pos_v)\n",
    "    test_neg=edges_to_lists(test_neg_u, test_neg_v)\n",
    "    train_neg=edges_to_lists(train_neg_u, train_neg_v)\n",
    "    \n",
    "    featureMatrix=graph.ndata['feat']\n",
    "        \n",
    "    \n",
    "    return adj, adj_train, adj_test, featureMatrix, train_graph, train_pos, test_pos, train_neg, test_neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(model, adj, feat, epoch, optimizer, device='cpu'):\n",
    "    if optimizer is None:\n",
    "        model.eval()\n",
    "    else:\n",
    "        model.train()\n",
    "    \n",
    "    generated_prob, mu, sigma, latent_representation, Z, epsilon=model.forward(adj.to(device), feat.to(device))\n",
    "    loss_rec, loss_prior, loss_post=loss(adj, mu, sigma, Z, latent_representation)\n",
    "    loss=loss_rec+loss_prior+loss_post\n",
    "    \n",
    "    WarmingUP=np.min([epoch/300, 1])\n",
    "    reg=(loss_post-loss_prior) * WarmingUP / (adj.size(0)**2)\n",
    "    loss_train=loss_rec+WarmingUP*reg\n",
    "    \n",
    "    if optimizer is not None:\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "    return latent_representation, generated_prob, loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc(embedding, pos_edges, neg_edges):\n",
    "    pos_array=np.array(pos_edges) #(2, #positive edges)\n",
    "    neg_array=np.array(neg_edges) #(2, #negative edges)\n",
    "    emb_pos_head=embedding[:, pos_array[0], :]\n",
    "    emb_pos_tail=embedding[:, pos_array[1], :]\n",
    "    preds_pos=np.einsum('abc, abc->ab', emb_pos_head, emb_pos_tail)\n",
    "    \n",
    "    emb_neg_head=embedding[:, neg_array[0], :]\n",
    "    emb_neg_tail=embedding[:, neg_array[1], :]\n",
    "    preds_neg=np.einsum('abc, abc->ab', emb_neg_head, emb_neg_tail)\n",
    "    \n",
    "    preds=torch.cat([preds_pos, preds_neg], dim=0)\n",
    "    labels=torch.cat([torch.ones(preds_pos.shape[-1]), torch.zeros(preds_neg.shape[-1])])\n",
    "    \n",
    "    roc=torch.Tensor([roc_auc_score(labels, pred.flatten()) for pred in torch.split(preds, embedding.shape[0])].mean())\n",
    "    \n",
    "    return roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj, adj_train, adj_test, featMatrix, train_graph, train_pos, test_pos, train_neg, test_neg=preprocess(graph)\n",
    "adj_label=adj_train+sp.eye(adj_train.shape[0])\n",
    "adj_label=torch.FloatTensor(adj_label.toarray())\n",
    "  \n",
    "model=SIGVAE_GIN(Lu=1, \n",
    "                Lmu=1, \n",
    "                Lsigma=1, \n",
    "                input_dim=adj_train.shape[0], \n",
    "                output_dim_u=[32], \n",
    "                output_dim_mu=[16], \n",
    "                output_dim_sigma=[16],\n",
    "                K=15,\n",
    "                J=20,\n",
    "                noise_dim=64,\n",
    "                activation=nn.ReLU,\n",
    "                dropout=0)\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "epoch=100\n",
    "    \n",
    "for epc in range(epoch):\n",
    "    t=time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    generated_prob, mu, sigma, latent_representation, z_proc, epsilon=model(adj_train, featureMatrix)\n",
    "    loss_accumulate=0\n",
    "    latent_representation, generated_prob, loss_train=step(model, adj_train, featMatrix, epc, optimizer, device='cpu')\n",
    "    loss_accumulate+=loss_train\n",
    "    \n",
    "    z_proc=z_proc.numpy()\n",
    "    roc=get_auc(z_proc, train_pos, train_neg)\n",
    "    \n",
    "    print(\"Epoch : \", '%d' %(epoch+1), \"loss=\", \"%f\".format(loss_train.item()),\n",
    "          \"time=\", \"%f\".format(time.time()-t))\n",
    "    \n",
    "    if((epoch+1) % 10 == 0):\n",
    "            model.eval()\n",
    "            generated_prob, mu, sigma, latent_representation, z_proc, epsilon=model(adj_train, featureMatrix)\n",
    "            z_proc = z_proc.numpy()\n",
    "            roc_score = get_auc(z_proc, test_pos, test_neg)\n",
    "            rslt = \"Test ROC score: %f\".format(roc_score)\n",
    "            print(\"\\n\", rslt, \"\\n\")\n",
    "    #latent_representation, generated_prob, loss_train=step(model, adj_train, epoch, optimizer )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ba116f7bd82e3a920c573cc5e25ed4764817b5f58b2642ba6fbd57f2ebc1da01"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('SIGVAE')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
