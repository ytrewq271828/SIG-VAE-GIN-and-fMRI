{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sigvae_transformer_experiment.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPAZoKU+XBFgp4u1e0tBlpa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":81611,"status":"ok","timestamp":1655005048210,"user":{"displayName":"김준엽","userId":"13244491849873010810"},"user_tz":-540},"id":"HYuDMzcdvBMm","outputId":"e0ad435a-7816-46e4-a711-16869d0751d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://data.dgl.ai/wheels/repo.html\n","Collecting dgl-cu113\n","  Downloading https://data.dgl.ai/wheels/dgl_cu113-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (220.6 MB)\n","\u001b[K     |████████████████████████████████| 220.6 MB 35 kB/s \n","\u001b[?25hCollecting dglgo\n","  Downloading dglgo-0.0.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 4.9 MB/s \n","\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl-cu113) (2.6.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu113) (2.23.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu113) (1.4.1)\n","Collecting psutil>=5.8.0\n","  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n","\u001b[K     |████████████████████████████████| 281 kB 68.6 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from dgl-cu113) (4.64.0)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu113) (1.21.6)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu113) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu113) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu113) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu113) (2022.5.18.1)\n","Collecting PyYAML>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 64.9 MB/s \n","\u001b[?25hCollecting autopep8>=1.6.0\n","  Downloading autopep8-1.6.0-py2.py3-none-any.whl (45 kB)\n","\u001b[K     |████████████████████████████████| 45 kB 3.6 MB/s \n","\u001b[?25hCollecting typer>=0.4.0\n","  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n","Collecting ruamel.yaml>=0.17.20\n","  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n","\u001b[K     |████████████████████████████████| 109 kB 84.3 MB/s \n","\u001b[?25hCollecting isort>=5.10.1\n","  Downloading isort-5.10.1-py3-none-any.whl (103 kB)\n","\u001b[K     |████████████████████████████████| 103 kB 70.8 MB/s \n","\u001b[?25hCollecting numpydoc>=1.1.0\n","  Downloading numpydoc-1.4.0-py3-none-any.whl (51 kB)\n","\u001b[K     |████████████████████████████████| 51 kB 509 kB/s \n","\u001b[?25hCollecting pydantic>=1.9.0\n","  Downloading pydantic-1.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n","\u001b[K     |████████████████████████████████| 11.1 MB 63.3 MB/s \n","\u001b[?25hCollecting pycodestyle>=2.8.0\n","  Downloading pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)\n","\u001b[K     |████████████████████████████████| 42 kB 908 kB/s \n","\u001b[?25hCollecting toml\n","  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.7/dist-packages (from numpydoc>=1.1.0->dglgo) (2.11.3)\n","Collecting sphinx>=3.0\n","  Downloading Sphinx-5.0.1-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 62.8 MB/s \n","\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic>=1.9.0->dglgo) (4.2.0)\n","Collecting ruamel.yaml.clib>=0.2.6\n","  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n","\u001b[K     |████████████████████████████████| 546 kB 24.3 MB/s \n","\u001b[?25hRequirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2.2.0)\n","Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2.6.1)\n","Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (21.3)\n","Collecting sphinxcontrib-qthelp\n","  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 7.0 MB/s \n","\u001b[?25hCollecting sphinxcontrib-jsmath\n","  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (0.7.12)\n","Collecting sphinxcontrib-htmlhelp>=2.0.0\n","  Downloading sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl (100 kB)\n","\u001b[K     |████████████████████████████████| 100 kB 9.6 MB/s \n","\u001b[?25hRequirement already satisfied: babel>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2.10.1)\n","Requirement already satisfied: docutils<0.19,>=0.14 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (0.17.1)\n","Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.1.5)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (4.11.4)\n","Collecting sphinxcontrib-devhelp\n","  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n","\u001b[K     |████████████████████████████████| 84 kB 3.2 MB/s \n","\u001b[?25hCollecting sphinxcontrib-applehelp\n","  Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n","\u001b[K     |████████████████████████████████| 121 kB 98.1 MB/s \n","\u001b[?25hRequirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel>=1.3->sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2022.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->sphinx>=3.0->numpydoc>=1.1.0->dglgo) (3.8.0)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer>=0.4.0->dglgo) (7.1.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->sphinx>=3.0->numpydoc>=1.1.0->dglgo) (3.0.9)\n","Installing collected packages: sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, toml, sphinx, ruamel.yaml.clib, pycodestyle, typer, ruamel.yaml, PyYAML, pydantic, psutil, numpydoc, isort, autopep8, dglgo, dgl-cu113\n","  Attempting uninstall: sphinx\n","    Found existing installation: Sphinx 1.8.6\n","    Uninstalling Sphinx-1.8.6:\n","      Successfully uninstalled Sphinx-1.8.6\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: psutil\n","    Found existing installation: psutil 5.4.8\n","    Uninstalling psutil-5.4.8:\n","      Successfully uninstalled psutil-5.4.8\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed PyYAML-6.0 autopep8-1.6.0 dgl-cu113-0.8.2 dglgo-0.0.1 isort-5.10.1 numpydoc-1.4.0 psutil-5.9.1 pycodestyle-2.8.0 pydantic-1.9.1 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.6 sphinx-5.0.1 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 toml-0.10.2 typer-0.4.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["psutil","sphinxcontrib"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.12.18-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 32.4 MB/s \n","\u001b[?25hCollecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Collecting setproctitle\n","  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 56.2 MB/s \n","\u001b[?25hCollecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.9.1)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.5.12-py2.py3-none-any.whl (145 kB)\n","\u001b[K     |████████████████████████████████| 145 kB 77.2 MB/s \n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.2.0)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.5.18.1)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=ee1fd293ea15fdb49a880fe0373640d8513155e863eaaf0ba454452c2bdc5d58\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n","Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.12 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 wandb-0.12.18\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install dgl-cu113 dglgo -f https://data.dgl.ai/wheels/repo.html\n","#!pip install torchviz\n","!pip install wandb\n","!wandb login"]},{"cell_type":"code","source":["import sys\n","sys.path.insert(0,'/content/drive/My Drive/SIG-VAE-GIN-and-fMRI/SIG-VAE-GIN-and-fMRI')"],"metadata":{"id":"xQDJHCOcGJ0V","executionInfo":{"status":"ok","timestamp":1654941143716,"user_tz":-540,"elapsed":5,"user":{"displayName":"김준엽","userId":"13244491849873010810"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1655005053566,"user":{"displayName":"김준엽","userId":"13244491849873010810"},"user_tz":-540},"id":"Ttry1fIBKbfS","outputId":"e39cf2aa-e03d-429f-d3b5-d24d17dfcf1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}],"source":["%ls\n","%load_ext autoreload\n","%autoreload 2/"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10023,"status":"ok","timestamp":1655005067918,"user":{"displayName":"김준엽","userId":"13244491849873010810"},"user_tz":-540},"id":"XUWkpYeBTsK4","outputId":"fdb430a1-9d4c-482e-9f7d-591645a010d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive\n","/content/drive/MyDrive\n","/content/drive/MyDrive/SIG-VAE-GIN-and-fMRI\n","/content/drive/MyDrive/SIG-VAE-GIN-and-fMRI/SIG-VAE-GIN-and-fMRI\n"]},{"output_type":"stream","name":"stderr","text":["DGL backend not selected or invalid.  Assuming PyTorch for now.\n"]},{"output_type":"stream","name":"stdout","text":["Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"]}],"source":["%cd drive\n","%cd MyDrive\n","%cd SIG-VAE-GIN-and-fMRI\n","%cd SIG-VAE-GIN-and-fMRI\n","from sigvaemodel_transformer import *\n","from loss import *"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"GzE106uMKf7o","executionInfo":{"status":"ok","timestamp":1655005069977,"user_tz":-540,"elapsed":5,"user":{"displayName":"김준엽","userId":"13244491849873010810"}}},"outputs":[],"source":["%reload_ext autoreload\n","from sigvaemodel_transformer import *\n","from loss import loss as loss_function\n","#from graph_transformer_edge_layer import *\n","from graph_transformer_layer import *\n","from mlp_readout_layer import *\n","#from loss import get_rec"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2186,"status":"ok","timestamp":1655005086005,"user":{"displayName":"김준엽","userId":"13244491849873010810"},"user_tz":-540},"id":"T5FmKW1Z726f","outputId":"86277e85-3382-4e36-d767-3e7c32c9ccb7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading /root/.dgl/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...\n","Extracting file to /root/.dgl/cora_v2\n","Finished data loading and preprocessing.\n","  NumNodes: 2708\n","  NumEdges: 10556\n","  NumFeats: 1433\n","  NumClasses: 7\n","  NumTrainingSamples: 140\n","  NumValidationSamples: 500\n","  NumTestSamples: 1000\n","Done saving data into cached files.\n","10556\n","torch.Size([1, 2708, 1433])\n","tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","         ...,\n","         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0526, 0.0000]]])\n"]}],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import dgl.data\n","import copy\n","import networkx as nx\n","import scipy.sparse as sp\n","from sklearn.metrics import average_precision_score, roc_curve, precision_recall_curve, roc_auc_score\n","import sigvaemodel_transformer\n","import loss\n","import time\n","import wandb\n","import torch.optim as optim\n","import gc\n","from matplotlib import pyplot\n","#from torchviz import make_dot\n","\n","CoraDataset=dgl.data.CoraGraphDataset(reverse_edge=False)\n","graph=CoraDataset[0]\n","u, v=graph.edges()\n","print(len(u))\n","featureMatrix=graph.ndata['feat']\n","featureMatrix=featureMatrix.view(1, featureMatrix.shape[0], featureMatrix.shape[1])\n","\n","print(featureMatrix.size())\n","print(featureMatrix)\n","graph.to('cuda')\n","config=dict(\n","    learning_rate=0.005,\n","    architecture=\"GIN\",\n","    dataset=\"Cora\",\n","    noise_dim=64,\n","    u_dim = 32,\n","    latent_dim = 32,\n","    lap_pos_enc_dim=4,\n","    warming_up=200,\n","    K=15,\n","    J=15,\n","    epoch=2000\n",")\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"nZteNAu3726m","executionInfo":{"status":"ok","timestamp":1655005087922,"user_tz":-540,"elapsed":6,"user":{"displayName":"김준엽","userId":"13244491849873010810"}}},"outputs":[],"source":["def edges_to_lists(headMatrix, tailMatrix):\n","    results=[]\n","    assert len(headMatrix)==len(tailMatrix)\n","    hlength=len(headMatrix)\n","    for i in range(hlength):\n","        results.append([headMatrix[i], tailMatrix[i]])\n","    return results"]},{"cell_type":"code","source":["def laplacian_positional_encoding(g, pos_enc_dim):\n","    \"\"\"\n","        Graph positional encoding v/ Laplacian eigenvectors\n","    \"\"\"\n","\n","    # Laplacian\n","    A = g.adjacency_matrix_scipy(return_edge_ids=False).astype(float)\n","    N = sp.diags(dgl.backend.asnumpy(g.in_degrees()).clip(1) ** -0.5, dtype=float)\n","    L = sp.eye(g.number_of_nodes()) - N * A * N\n","\n","    # Eigenvectors with scipy\n","    #EigVal, EigVec = sp.linalg.eigs(L, k=pos_enc_dim+1, which='SR')\n","    EigVal, EigVec = sp.linalg.eigs(L, k=pos_enc_dim+1, which='SR', tol=1e-2) # for 40 PEs\n","    EigVec = EigVec[:, EigVal.argsort()] # increasing order\n","    g.ndata['lap_pos_enc'] = torch.from_numpy(EigVec[:,1:pos_enc_dim+1]).float() \n","\n","    return g"],"metadata":{"id":"sPSN87qDNFu9","executionInfo":{"status":"ok","timestamp":1655005089574,"user_tz":-540,"elapsed":6,"user":{"displayName":"김준엽","userId":"13244491849873010810"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"-h16ITog726n","executionInfo":{"status":"ok","timestamp":1655005091773,"user_tz":-540,"elapsed":6,"user":{"displayName":"김준엽","userId":"13244491849873010810"}}},"outputs":[],"source":["def preprocess(graph, pos_enc_dim):\n","    N=graph.num_nodes()\n","    numE=graph.number_of_edges()\n","    halfnumE=int(numE/2)\n","    \n","    u, v=graph.edges()\n","    #graph.add_edges(v, u, graph.edata)\n","    #u, v=graph.edges()\n","    #numEtimes2=graph.number_of_edges()\n","    #print(numEtimes2)\n","    idx=np.arange(halfnumE)\n","    testidx=np.random.permutation(idx)\n","    testSize=int(len(idx)/10)\n","    validation_size=int(len(idx)/20)\n","    train_size=numE-testSize-validation_size\n","    '''\n","    adj1=sp.coo_matrix((np.ones(len(u)), (u.detach().cpu().numpy(), v.detach().cpu().numpy())))\n","    adj2=sp.coo_matrix((np.ones(len(u)), (v.detach().cpu().numpy(), u.detach().cpu().numpy())))\n","    adj=adj1+adj2\n","    adj=torch.Tensor(adj.todense())\n","    print(adj)\n","    adj[adj==2]=1\n","    '''\n","    adj=sp.coo_matrix((np.ones(len(u)), (u.detach().cpu().numpy(), v.detach().cpu().numpy())))\n","    adj=torch.Tensor(adj.todense())\n","    adj_upper=torch.triu(adj, diagonal=1)\n","    adj_lower=torch.tril(adj, diagonal=-1)\n","\n","    uUpper, vUpper=torch.where(adj_upper!=0)\n","    print(\"^^^^^^^^^^^^^^^^6666\")\n","    print(uUpper.shape)\n","    print(vUpper.shape)\n","    test_pos_u, test_pos_v=uUpper[testidx[:testSize]], vUpper[testidx[:testSize]]\n","    train_pos_u, train_pos_v = uUpper[testidx[testSize:halfnumE-validation_size]], vUpper[testidx[testSize:halfnumE-validation_size]]\n","    validation_pos_u, validation_pos_v=uUpper[testidx[halfnumE-validation_size:]], vUpper[testidx[halfnumE-validation_size:]]\n","    \n","    #print(\"&&&&&&&&&&&&&&&&&&&&&\")\n","    #print(adj.shape)\n","    #print(torch.max(adj))\n","    adj_neg_upper=torch.triu(1-adj_upper, diagonal=1)\n","    neg_u, neg_v=torch.where(adj_neg_upper!=0)\n","    #print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n","    #print(len(neg_u))\n","    #print(len(neg_v))\n","    neg_testidx=np.random.choice(len(neg_u), halfnumE)\n","    test_neg_u, test_neg_v=neg_u[neg_testidx[:testSize]], neg_v[neg_testidx[:testSize]]\n","    train_neg_u, train_neg_v=neg_u[neg_testidx[testSize:halfnumE-validation_size]], neg_v[neg_testidx[testSize:halfnumE-validation_size]]\n","    validation_neg_u, validation_neg_v=neg_u[neg_testidx[halfnumE-validation_size:]], neg_v[neg_testidx[halfnumE-validation_size:]]\n","    #print(test_neg_u)\n","    #print(test_neg_v)\n","    \n","    adj_train1=sp.coo_matrix((np.ones(len(train_pos_u)), (train_pos_u.detach().cpu().numpy(), train_pos_v.detach().cpu().numpy())),shape=(N, N))\n","    adj_train2=sp.coo_matrix((np.ones(len(train_pos_u)), (train_pos_v.detach().cpu().numpy(), train_pos_u.detach().cpu().numpy())),shape=(N, N))\n","    adj_train=adj_train1+adj_train2\n","    #adj_train[adj_train==2]=1\n","    #adj_train=adj_train-sp.dia_matrix((adj_train.diagonal()[np.newaxis, :], [0]), shape=adj_train.shape)\n","    adj_train=torch.Tensor(adj_train.todense())\n","    print(torch.max(adj_train))\n","    \n","    adj_test1=sp.coo_matrix((np.ones(len(test_pos_u)), (test_pos_u.detach().cpu().numpy(), test_pos_v.detach().cpu().numpy())),shape=(N,N))\n","    adj_test2=sp.coo_matrix((np.ones(len(test_pos_u)), (test_pos_v.detach().cpu().numpy(), test_pos_u.detach().cpu().numpy())),shape=(N,N))\n","    adj_test=adj_test1+adj_test2\n","    #adj_test[adj_test==2]=1\n","    #adj_test=adj_test-sp.dia_matrix((adj_test.diagonal()[np.newaxis, :], [0]), shape=adj_test.shape)\n","    adj_test=torch.Tensor(adj_test.todense())\n","    print(torch.max(adj_test))\n","\n","    adj_validation1=sp.coo_matrix((np.ones(len(validation_pos_u)), (validation_pos_u.detach().cpu().numpy(), validation_pos_v.detach().cpu().numpy())),shape=(N,N))\n","    adj_validation2=sp.coo_matrix((np.ones(len(validation_pos_u)), (validation_pos_v.detach().cpu().numpy(), validation_pos_u.detach().cpu().numpy())),shape=(N,N))\n","    adj_validation=adj_validation1+adj_validation2\n","    #adj_validation[adj_validation==2]=1\n","    #adj_validation=adj_validation-sp.dia_matrix((adj_validation.diagonal()[np.newaxis, :], [0]), shape=adj_validation.shape)\n","    adj_validation=torch.Tensor(adj_validation.todense())\n","    print(torch.max(adj_validation))\n","\n","\n","    adj_train_neg1=sp.coo_matrix((np.ones(len(train_neg_u)), (train_neg_u, train_neg_v)),shape=(N, N))\n","    adj_train_neg2=sp.coo_matrix((np.ones(len(train_neg_u)), (train_neg_v, train_neg_u)),shape=(N, N))\n","    adj_train_neg=adj_train_neg1+adj_train_neg2\n","    \n","    #adj_train=adj_train-sp.dia_matrix((adj_train.diagonal()[np.newaxis, :], [0]), shape=adj_train.shape)\n","    adj_train_neg=torch.Tensor(adj_train_neg.todense())\n","    adj_train_neg[adj_train_neg==2]=1\n","    print(torch.max(adj_train_neg))\n","    \n","    adj_test_neg1=sp.coo_matrix((np.ones(len(test_neg_u)), (test_neg_u, test_neg_v)),shape=(N,N))\n","    adj_test_neg2=sp.coo_matrix((np.ones(len(test_neg_u)), (test_neg_v, test_neg_u)),shape=(N,N))\n","    adj_test_neg=adj_test_neg1+adj_test_neg2\n","    adj_test[adj_test==2]=1\n","    #adj_test=adj_test-sp.dia_matrix((adj_test.diagonal()[np.newaxis, :], [0]), shape=adj_test.shape)\n","    adj_test_neg=torch.Tensor(adj_test_neg.todense())\n","    print(torch.max(adj_test_neg))\n","\n","    adj_validation_neg1=sp.coo_matrix((np.ones(len(validation_neg_u)), (validation_neg_u, validation_pos_v)),shape=(N,N))\n","    adj_validation_neg2=sp.coo_matrix((np.ones(len(validation_neg_u)), (validation_neg_v, validation_pos_u)),shape=(N,N))\n","    adj_validation_neg=adj_validation_neg1+adj_validation_neg2\n","    adj_validation[adj_validation==2]=1\n","    #adj_validation=adj_validation-sp.dia_matrix((adj_validation.diagonal()[np.newaxis, :], [0]), shape=adj_validation.shape)\n","    adj_validation_neg=torch.Tensor(adj_validation_neg.todense())\n","    print(torch.max(adj_validation_neg))\n","\n","\n","    train_u, train_v=torch.where(adj_train!=0)\n","    train_graph=dgl.graph((torch.hstack((train_u, train_v)), torch.hstack((train_v, train_u))), num_nodes=N)\n","    \n","    #train_graph=dgl.remove_edges(graph, np.hstack((testidx[:testSize],testidx[numE-validation_size:], (testidx[:testSize]+numE), (testidx[numE-validation_size:]+numE))))\n","    #train_graph=dgl.remove_edges(train_graph_temp, np.hstack((testidx[:testSize], testidx[numE-validation_size:]+numE)))\n","    test_u, test_v=torch.where(adj_test!=0)\n","    #test_graph=dgl.graph((torch.hstack((test_u, test_v)), torch.hstack((test_v, test_u))))\n","    #test_graph=dgl.remove_edges(graph, np.hstack((testidx[testSize:], (testidx[testSize:]+numE))))\n","    #test_graph=dgl.remove_edges(test_graph_temp, testidx[testSize:]+numE)\n","    validation_u, validation_v=torch.where(adj_validation!=0)\n","    #validation_graph=dgl.graph((torch.hstack((validation_u, validation_v)), torch.hstack((validation_v, validation_u))))\n","    #validation_graph=dgl.remove_edges(graph, np.hstack((testidx[:numE-validation_size], (testidx[:numE-validation_size]+numE))))\n","    #validation_graph=dgl.remove_edges(validation_graph_temp ,testidx[:numE-validation_size]+numE)\n","    \n","    train_neg_u, train_neg_v=torch.where(adj_train_neg!=0)\n","    test_neg_u, test_neg_v=torch.where(adj_test_neg!=0)\n","    validation_neg_u, validation_neg_v=torch.where(adj_validation_neg!=0)\n","    '''\n","    train_pos=edges_to_lists(train_pos_u, train_pos_v)\n","    test_pos=edges_to_lists(test_pos_u, test_pos_v)\n","    test_neg=edges_to_lists(test_neg_u, test_neg_v)\n","    train_neg=edges_to_lists(train_neg_u, train_neg_v)\n","    validation_pos=edges_to_lists(validation_pos_u, validation_pos_v)\n","    validation_neg=edges_to_lists(validation_neg_u, validation_neg_v)\n","    '''\n","    '''\n","    train_pos=edges_to_lists(train_pos_u, train_pos_v)+edges_to_lists(train_pos_v, train_pos_u)\n","    test_pos=edges_to_lists(test_pos_u, test_pos_v)+edges_to_lists(test_pos_v, test_pos_u)\n","    test_neg=edges_to_lists(test_neg_u, test_neg_v)+edges_to_lists(test_neg_v, test_neg_u)\n","    train_neg=edges_to_lists(train_neg_u, train_neg_v)+edges_to_lists(train_neg_v, train_neg_u)\n","    validation_pos=edges_to_lists(validation_pos_u, validation_pos_v)+edges_to_lists(validation_pos_v, validation_pos_u)\n","    validation_neg=edges_to_lists(validation_neg_u, validation_neg_v)+edges_to_lists(validation_neg_v, validation_neg_u)\n","    '''\n","    train_pos=edges_to_lists(train_u, train_v)\n","    test_pos=edges_to_lists(test_u, test_v)\n","    validation_pos=edges_to_lists(validation_u, validation_v)\n","    train_neg=edges_to_lists(train_neg_u, train_neg_v)\n","    test_neg=edges_to_lists(test_neg_u, test_neg_v)\n","    validation_neg=edges_to_lists(validation_neg_u, validation_neg_v)\n","\n","    print(len(validation_pos))\n","    print(len(validation_neg))\n","    featureMatrix=graph.ndata['feat']\n","    print(\"****************\")\n","    print(featureMatrix.shape[0])\n","    featureMatrix=featureMatrix.view(1, featureMatrix.shape[0], featureMatrix.shape[1]).to('cuda')\n","\n","    train_graph=laplacian_positional_encoding(train_graph, pos_enc_dim)\n","    #test_graph=laplacian_positional_encoding(test_graph, pos_enc_dim)\n","    #validation_graph=laplacian_positional_encoding(validation_graph, pos_enc_dim)\n","\n","    return graph, adj, adj_train, adj_validation, adj_test, featureMatrix, train_graph, train_pos, validation_pos, test_pos, train_neg, validation_neg, test_neg\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Xz2zVKFb726o","executionInfo":{"status":"ok","timestamp":1655005094131,"user_tz":-540,"elapsed":6,"user":{"displayName":"김준엽","userId":"13244491849873010810"}}},"outputs":[],"source":["def step(model, adj, adj_label, feat, input_graph, batch_graph, epoch, K, J, weight, norm, dropout, optimizer, scheduler, device):\n","  #global loss\n","    if optimizer is None:\n","        with torch.no_grad():\n","          model.eval()\n","    else:\n","        model.train()\n","        optimizer.zero_grad()\n","    WU=torch.min(torch.Tensor([epoch/200., 1.]))\n","    \n","    #generated_prob, mu, sigma, latent_representation, Z, epsilon=model.forward(adj.to(device), feat.to(device), input_graph)\n","    generated_prob, mu, sigma, latent_representation, Z, epsilon, rk=model.forward(adj.to(device), feat.to(device), input_graph, batch_graph)\n","    loss=loss_function(generated_prob, adj_label, mu, sigma, Z, epsilon, latent_representation, K, J, WU, norm, weight, dropout, device=device)\n","    \n","    #loss_rec, loss_prior, loss_post=loss_function(generated_prob, adj_label, mu, sigma, Z, epsilon, latent_representation, K, J, norm, weight, dropout, device=device)\n","    #reg=(loss_post-loss_prior) / (adj.size(0)**2)\n","    #loss=loss_rec+reg\n","    \n","    #print(generated_prob.shape)\n","    #print(adj.shape)\n","    #loss=loss_rec+loss_prior+loss_post\n","    \n","    #WarmingUP=np.min([epoch/300,1])\n","    #reg=(loss_post-loss_prior) * WarmingUP / (adj.size(0)**2)\n","    #loss=loss_rec+WarmingUP*reg\n","    \n","    \n","    if optimizer is not None:\n","        #make_dot(loss,params=dict(model.named_parameters()))\n","        loss.backward()\n","        optimizer.step()\n","        if scheduler is not None:\n","          scheduler.step()\n","    del mu\n","    del sigma\n","    del epsilon\n","    return latent_representation, generated_prob, loss, Z, rk"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"aba_UkNc726q","executionInfo":{"status":"ok","timestamp":1655005097111,"user_tz":-540,"elapsed":5,"user":{"displayName":"김준엽","userId":"13244491849873010810"}}},"outputs":[],"source":["def get_auc(embedding, adj_orig, rk, pos_array, neg_array, decoder_type):\n","    \n","    def dc(x):\n","      if decoder_type==\"ip\":\n","        return 1/(1+torch.exp(-x))\n","      elif decoder_type==\"bp\":\n","        return 1-torch.exp(-torch.exp(x))\n","    \n","    J=embedding.shape[0]\n","    rk_expand=torch.tile(torch.diag(rk), (J, 1, 1))\n","    X=torch.transpose(embedding, 1, 2)\n","    X=torch.bmm(rk_expand, X)\n","    X=torch.bmm(embedding, X)\n","    X=torch.clamp(X, min=float('-inf'), max=10)\n","    adj_rec=1-torch.exp(-torch.exp(X))\n","    #print(\"@@@@@@@@@@@@@@@@@@@@\")\n","    #print(adj_rec)\n","    '''\n","    adj_rec=torch.zeros(J, embedding.shape[1], embedding.shape[1])\n","    for i, emb in enumerate(embedding):\n","      tmp = torch.matmul(torch.diag(rk), emb.t())\n","      adj_rec_sub = 1 - torch.exp(- torch.exp(torch.matmul(emb, tmp)))\n","      adj_rec[i]=adj_rec_sub\n","    '''\n","    preds_pos=torch.zeros(J, pos_array.shape[1])\n","    for i, e in enumerate(pos_array.t()):\n","      preds_pos[:,i]=adj_rec[:,e[0], e[1]]\n","    \n","    preds_neg=torch.zeros(J, neg_array.shape[1])\n","    for i, e in enumerate(neg_array.t()):\n","      preds_neg[:,i]=adj_rec[:, e[0], e[1]]\n","\n","    #preds_pos=adj_rec[:, pos_array[0], pos_array[1]]\n","    #preds_neg=adj_rec[:, neg_array[0], neg_array[1]]\n","    '''\n","    emb_pos_head=embedding[:, pos_array[0], :]\n","    emb_pos_tail=embedding[:, pos_array[1], :]\n","    preds_pos=dc(torch.einsum('abc, abc->ab', emb_pos_head, emb_pos_tail))\n","    emb_neg_head=embedding[:, neg_array[0], :]\n","    emb_neg_tail=embedding[:, neg_array[1], :]\n","    preds_neg=dc(torch.einsum('abc, abc->ab', emb_neg_head, emb_neg_tail))\n","    #preds_neg=torch.einsum('abc, abc->ab', emb_neg_head, emb_neg_tail)\n","    '''\n","\n","    preds=torch.hstack([preds_pos, preds_neg]).detach().cpu().numpy()\n","    labels=torch.hstack([torch.ones(preds_pos.shape[-1]), torch.zeros(preds_neg.shape[-1])]).detach().cpu().numpy()\n","    #print(preds[0])\n","    #print(preds[1])\n","    roc=torch.Tensor([roc_auc_score(labels, pred.flatten()) for pred in np.vsplit(preds, embedding.shape[0])]).mean()\n","    avg_precision=torch.Tensor([average_precision_score(labels, pred.flatten()) for pred in np.vsplit(preds, embedding.shape[0])]).mean()\n","    '''\n","    fpr_accumulate=0\n","    tpr_accumulate=0\n","    recall_accumulate=0\n","    precision_accumulate=0\n","    for pred in np.vsplit(preds,J):\n","      fpr, tpr, _=roc_curve(labels, pred.flatten())\n","      precision, recall, _=precision_recall_curve(labels, pred.flatten())\n","      fpr_accumulate+=fpr.mean()\n","      tpr_accumulate+=tpr.mean()\n","      recall_accumulate+=recall.mean()\n","      precision_accumulate+=precision.mean()\n","    fpr_mean=fpr_accumulate/J\n","    tpr_mean=tpr_accumulate/J\n","    recall_mean=recall_accumulate/J\n","    precision_mean=precision_accumulate/J\n","    '''\n","    #precision, recall=torch.Tensor([precision_recall_curve(labels, pred.flatten()) for pred in np.vsplit(preds, embedding.shape[0])])\n","    #accuracy=torch.Tensor([accuracy_score(labels, pred.flatten()) for pred in np.vsplit(preds, embedding.shape[0])]).mean()\n","    #precision=torch.Tensor([precision_score(labels, pred) for pred in np.vsplit(preds, embedding.shape[0])]).mean()\n","    #recall=torch.Tensor([recall_score(labels, pred) for pred in np.vsplit(preds, embedding.shape[0])]).mean()\n","    #precision=precision.mean()\n","    #recall=recall.mean()\n","    #fpr=fpr.mean()\n","    del adj_rec\n","    del preds_pos\n","    del preds_neg\n","    del preds\n","    del labels\n","\n","    return roc, avg_precision #, precision_mean, recall_mean, fpr_mean, tpr_mean"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"bdSI00x3726r","outputId":"adcb7719-f729-4193-8dda-90a81a835d61"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mytrewq271828\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.18"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/My Drive/SIG-VAE-GIN-and-fMRI/SIG-VAE-GIN-and-fMRI/wandb/run-20220612_033818-iaz0gyzn</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/ytrewq271828/SIG-VAE-GIN-and-fMRI/runs/iaz0gyzn\" target=\"_blank\">sparkling-dream-88</a></strong> to <a href=\"https://wandb.ai/ytrewq271828/SIG-VAE-GIN-and-fMRI\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["^^^^^^^^^^^^^^^^6666\n","torch.Size([5278])\n","torch.Size([5278])\n","tensor(1.)\n","tensor(1.)\n","tensor(1.)\n","tensor(1.)\n","tensor(1.)\n","tensor(1.)\n","526\n","526\n","****************\n","2708\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/dgl/heterograph.py:3721: DGLWarning: DGLGraph.adjacency_matrix_scipy is deprecated. Please replace it with:\n","\n","\tDGLGraph.adjacency_matrix(transpose, scipy_fmt=\"csr\").\n","\n","  'DGLGraph.adjacency_matrix(transpose, scipy_fmt=\"{}\").\\n'.format(fmt))\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  ../aten/src/ATen/native/Copy.cpp:239.)\n","  from ipykernel import kernelapp as app\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([2, 526])\n","torch.Size([2, 526])\n","%%%%%%%%%%%%%%%%%%%%%55\n","2708\n","Epoch :  1 loss= 1.423288 time= 4.793382 roc= 0.514194 average_precision 0.519463\n","Epoch :  2 loss= 1.320564 time= 3.138261 roc= 0.502028 average_precision 0.506447\n","Epoch :  3 loss= 1.346873 time= 3.133195 roc= 0.497272 average_precision 0.499759\n","Epoch :  4 loss= 1.246844 time= 3.137980 roc= 0.499140 average_precision 0.499347\n","Epoch :  5 loss= 1.185861 time= 3.156527 roc= 0.493011 average_precision 0.502190\n","Epoch :  6 loss= 1.188441 time= 3.151460 roc= 0.497162 average_precision 0.501389\n","Epoch :  7 loss= 1.181154 time= 3.134076 roc= 0.490452 average_precision 0.498635\n","Epoch :  8 loss= 1.220088 time= 3.130143 roc= 0.496811 average_precision 0.502088\n","Epoch :  9 loss= 1.100629 time= 3.133632 roc= 0.504651 average_precision 0.505258\n","Epoch :  10 loss= 1.195333 time= 3.130571 roc= 0.491698 average_precision 0.499901\n","Epoch :  11 loss= 1.228340 time= 3.191302 roc= 0.500729 average_precision 0.506510\n","Epoch :  12 loss= 1.094993 time= 3.121159 roc= 0.507186 average_precision 0.505774\n","Epoch :  13 loss= 1.232322 time= 3.148580 roc= 0.497921 average_precision 0.502030\n","Epoch :  14 loss= 1.154166 time= 3.154150 roc= 0.493989 average_precision 0.496003\n","Epoch :  15 loss= 1.121118 time= 3.153657 roc= 0.502048 average_precision 0.508146\n","Epoch :  16 loss= 1.211820 time= 3.130949 roc= 0.492958 average_precision 0.497178\n","Epoch :  17 loss= 1.161841 time= 3.147385 roc= 0.491549 average_precision 0.498206\n","Epoch :  18 loss= 1.222932 time= 3.156814 roc= 0.500141 average_precision 0.502172\n","Epoch :  19 loss= 1.067225 time= 3.137266 roc= 0.498862 average_precision 0.505368\n","Epoch :  20 loss= 1.071349 time= 3.140458 roc= 0.496532 average_precision 0.503926\n","\n"," Test ROC score: 0.500146    Test Precision score : 0.501785 \n","\n","Epoch :  21 loss= 1.135884 time= 3.137505 roc= 0.497413 average_precision 0.505236\n","Epoch :  22 loss= 1.046642 time= 3.157730 roc= 0.508391 average_precision 0.512068\n","Epoch :  23 loss= 1.073766 time= 3.132112 roc= 0.487709 average_precision 0.496461\n","Epoch :  24 loss= 0.966866 time= 3.132213 roc= 0.496991 average_precision 0.500966\n","Epoch :  25 loss= 1.011262 time= 3.132389 roc= 0.503428 average_precision 0.508412\n","Epoch :  26 loss= 0.966771 time= 3.144578 roc= 0.503844 average_precision 0.504126\n","Epoch :  27 loss= 0.999131 time= 3.173523 roc= 0.498496 average_precision 0.502969\n","Epoch :  28 loss= 1.058410 time= 3.137270 roc= 0.500679 average_precision 0.497944\n","Epoch :  29 loss= 1.004095 time= 3.138916 roc= 0.507726 average_precision 0.509497\n","Epoch :  30 loss= 0.976747 time= 3.137371 roc= 0.503578 average_precision 0.503222\n","Epoch :  31 loss= 1.022505 time= 3.152451 roc= 0.493193 average_precision 0.500553\n","Epoch :  32 loss= 1.072295 time= 3.191558 roc= 0.505675 average_precision 0.505255\n","Epoch :  33 loss= 1.049127 time= 3.136771 roc= 0.511050 average_precision 0.513844\n","Epoch :  34 loss= 1.032881 time= 3.164120 roc= 0.493265 average_precision 0.500324\n","Epoch :  35 loss= 0.976509 time= 3.154024 roc= 0.496066 average_precision 0.501054\n","Epoch :  36 loss= 1.064185 time= 3.146474 roc= 0.497055 average_precision 0.502414\n","Epoch :  37 loss= 0.951199 time= 3.157772 roc= 0.517011 average_precision 0.514939\n","Epoch :  38 loss= 0.944012 time= 3.145176 roc= 0.497936 average_precision 0.506381\n","Epoch :  39 loss= 1.003545 time= 3.150159 roc= 0.508801 average_precision 0.516269\n","Epoch :  40 loss= 0.987783 time= 3.147393 roc= 0.508906 average_precision 0.507336\n","\n"," Test ROC score: 0.505238    Test Precision score : 0.506751 \n","\n","Epoch :  41 loss= 0.951364 time= 3.163807 roc= 0.508985 average_precision 0.511621\n","Epoch :  42 loss= 0.901139 time= 3.148625 roc= 0.501531 average_precision 0.504994\n","Epoch :  43 loss= 0.958235 time= 3.177672 roc= 0.500692 average_precision 0.507089\n","Epoch :  44 loss= 0.847023 time= 3.163351 roc= 0.500752 average_precision 0.501298\n","Epoch :  45 loss= 0.868580 time= 3.155217 roc= 0.503135 average_precision 0.506480\n","Epoch :  46 loss= 0.894834 time= 3.159913 roc= 0.495188 average_precision 0.501703\n","Epoch :  47 loss= 0.882144 time= 3.169883 roc= 0.489939 average_precision 0.497218\n","Epoch :  48 loss= 0.850922 time= 3.160401 roc= 0.499330 average_precision 0.503202\n","Epoch :  49 loss= 0.848270 time= 3.140098 roc= 0.502191 average_precision 0.507543\n","Epoch :  50 loss= 0.875604 time= 3.193400 roc= 0.500102 average_precision 0.504916\n","Epoch :  51 loss= 0.873261 time= 3.154746 roc= 0.500644 average_precision 0.505362\n","Epoch :  52 loss= 0.864032 time= 3.147982 roc= 0.500793 average_precision 0.506664\n","Epoch :  53 loss= 0.865751 time= 3.128918 roc= 0.505322 average_precision 0.511348\n","Epoch :  54 loss= 0.846708 time= 3.168654 roc= 0.494701 average_precision 0.502213\n","Epoch :  55 loss= 0.850739 time= 3.150858 roc= 0.509191 average_precision 0.512202\n","Epoch :  56 loss= 0.848560 time= 3.169418 roc= 0.511541 average_precision 0.512619\n","Epoch :  57 loss= 0.875499 time= 3.149312 roc= 0.492834 average_precision 0.500311\n","Epoch :  58 loss= 0.851608 time= 3.148814 roc= 0.496021 average_precision 0.502784\n","Epoch :  59 loss= 0.853173 time= 3.162008 roc= 0.493460 average_precision 0.497540\n","Epoch :  60 loss= 0.837216 time= 3.163038 roc= 0.507347 average_precision 0.511625\n","\n"," Test ROC score: 0.493009    Test Precision score : 0.500288 \n","\n","Epoch :  61 loss= 0.822784 time= 3.143470 roc= 0.498819 average_precision 0.508253\n","Epoch :  62 loss= 0.824135 time= 3.172328 roc= 0.504034 average_precision 0.508029\n","Epoch :  63 loss= 0.813215 time= 3.148867 roc= 0.504541 average_precision 0.509564\n","Epoch :  64 loss= 0.789822 time= 3.156315 roc= 0.492335 average_precision 0.498690\n","Epoch :  65 loss= 0.810994 time= 3.143136 roc= 0.500199 average_precision 0.502985\n","Epoch :  66 loss= 0.797371 time= 3.149044 roc= 0.495232 average_precision 0.501571\n","Epoch :  67 loss= 0.804146 time= 3.163109 roc= 0.507525 average_precision 0.506995\n","Epoch :  68 loss= 0.787716 time= 3.151346 roc= 0.497328 average_precision 0.502421\n","Epoch :  69 loss= 0.786178 time= 3.173815 roc= 0.495311 average_precision 0.503765\n","Epoch :  70 loss= 0.795701 time= 3.167261 roc= 0.507872 average_precision 0.510900\n","Epoch :  71 loss= 0.780332 time= 3.171834 roc= 0.491232 average_precision 0.500454\n","Epoch :  72 loss= 0.781979 time= 3.179261 roc= 0.500585 average_precision 0.504297\n","Epoch :  73 loss= 0.777404 time= 3.148234 roc= 0.509635 average_precision 0.513503\n","Epoch :  74 loss= 0.786708 time= 3.148525 roc= 0.495288 average_precision 0.502657\n","Epoch :  75 loss= 0.776261 time= 3.162672 roc= 0.499845 average_precision 0.505789\n","Epoch :  76 loss= 0.776123 time= 3.196506 roc= 0.503720 average_precision 0.507466\n","Epoch :  77 loss= 0.782770 time= 3.170939 roc= 0.500760 average_precision 0.506752\n","Epoch :  78 loss= 0.789482 time= 3.156221 roc= 0.510939 average_precision 0.513848\n","Epoch :  79 loss= 0.779930 time= 3.144805 roc= 0.493514 average_precision 0.501431\n","Epoch :  80 loss= 0.762752 time= 3.167491 roc= 0.498880 average_precision 0.502696\n","\n"," Test ROC score: 0.495923    Test Precision score : 0.497375 \n","\n","Epoch :  81 loss= 0.784872 time= 3.182215 roc= 0.495608 average_precision 0.499429\n","Epoch :  82 loss= 0.774652 time= 3.301738 roc= 0.497045 average_precision 0.506431\n","Epoch :  83 loss= 0.762427 time= 3.149333 roc= 0.494699 average_precision 0.498609\n","Epoch :  84 loss= 0.767963 time= 3.148430 roc= 0.501665 average_precision 0.508320\n","Epoch :  85 loss= 0.760748 time= 3.153987 roc= 0.499167 average_precision 0.504395\n","Epoch :  86 loss= 0.763051 time= 3.152146 roc= 0.493143 average_precision 0.496572\n","Epoch :  87 loss= 0.761366 time= 3.158929 roc= 0.492953 average_precision 0.499960\n","Epoch :  88 loss= 0.766288 time= 3.157053 roc= 0.504836 average_precision 0.509247\n","Epoch :  89 loss= 0.767454 time= 3.176301 roc= 0.500871 average_precision 0.502379\n","Epoch :  90 loss= 0.760824 time= 3.149917 roc= 0.496283 average_precision 0.499540\n","Epoch :  91 loss= 0.760249 time= 3.164320 roc= 0.511220 average_precision 0.513796\n","Epoch :  92 loss= 0.759937 time= 3.156194 roc= 0.501707 average_precision 0.509170\n","Epoch :  93 loss= 0.771864 time= 3.159121 roc= 0.506796 average_precision 0.508447\n","Epoch :  94 loss= 0.766362 time= 3.170226 roc= 0.501563 average_precision 0.506472\n","Epoch :  95 loss= 0.761576 time= 3.149359 roc= 0.500747 average_precision 0.505739\n","Epoch :  96 loss= 0.758950 time= 3.145966 roc= 0.509485 average_precision 0.512834\n","Epoch :  97 loss= 0.762316 time= 3.160629 roc= 0.511517 average_precision 0.510646\n","Epoch :  98 loss= 0.764360 time= 3.177985 roc= 0.501549 average_precision 0.505809\n","Epoch :  99 loss= 0.763716 time= 3.155492 roc= 0.507686 average_precision 0.507707\n","Epoch :  100 loss= 0.758019 time= 3.156537 roc= 0.499895 average_precision 0.503949\n","\n"," Test ROC score: 0.503918    Test Precision score : 0.500121 \n","\n","Epoch :  101 loss= 0.757268 time= 3.159848 roc= 0.502153 average_precision 0.506444\n","Epoch :  102 loss= 0.760093 time= 3.166275 roc= 0.509573 average_precision 0.508585\n","Epoch :  103 loss= 0.757174 time= 3.165603 roc= 0.496761 average_precision 0.499823\n","Epoch :  104 loss= 0.756338 time= 3.157805 roc= 0.503892 average_precision 0.505599\n","Epoch :  105 loss= 0.756110 time= 3.140945 roc= 0.502662 average_precision 0.502229\n","Epoch :  106 loss= 0.755044 time= 3.164583 roc= 0.492782 average_precision 0.497694\n","Epoch :  107 loss= 0.756556 time= 3.150021 roc= 0.507611 average_precision 0.505469\n","Epoch :  108 loss= 0.755230 time= 3.185554 roc= 0.502708 average_precision 0.505468\n","Epoch :  109 loss= 0.753577 time= 3.173276 roc= 0.504330 average_precision 0.506191\n","Epoch :  110 loss= 0.753198 time= 3.184938 roc= 0.516924 average_precision 0.514679\n","Epoch :  111 loss= 0.751164 time= 3.199703 roc= 0.507883 average_precision 0.510061\n","Epoch :  112 loss= 0.750614 time= 3.196291 roc= 0.502480 average_precision 0.502575\n","Epoch :  113 loss= 0.757363 time= 3.177205 roc= 0.503401 average_precision 0.506618\n","Epoch :  114 loss= 0.755437 time= 3.177156 roc= 0.518315 average_precision 0.516297\n","Epoch :  115 loss= 0.753282 time= 3.164698 roc= 0.502810 average_precision 0.503030\n","Epoch :  116 loss= 0.751284 time= 3.146166 roc= 0.509944 average_precision 0.504556\n","Epoch :  117 loss= 0.752884 time= 3.164082 roc= 0.506179 average_precision 0.507132\n","Epoch :  118 loss= 0.754874 time= 3.142261 roc= 0.504375 average_precision 0.506559\n","Epoch :  119 loss= 0.759481 time= 3.168166 roc= 0.502523 average_precision 0.502205\n","Epoch :  120 loss= 0.749597 time= 3.171134 roc= 0.494394 average_precision 0.497924\n","\n"," Test ROC score: 0.505362    Test Precision score : 0.497339 \n","\n","Epoch :  121 loss= 0.750712 time= 3.155447 roc= 0.505495 average_precision 0.508755\n","Epoch :  122 loss= 0.750396 time= 3.177229 roc= 0.519208 average_precision 0.519794\n","Epoch :  123 loss= 0.747385 time= 3.141401 roc= 0.511103 average_precision 0.513424\n","Epoch :  124 loss= 0.750111 time= 3.166461 roc= 0.511536 average_precision 0.511432\n","Epoch :  125 loss= 0.744679 time= 3.157151 roc= 0.511554 average_precision 0.508696\n","Epoch :  126 loss= 0.747438 time= 3.142248 roc= 0.503236 average_precision 0.503919\n","Epoch :  127 loss= 0.744516 time= 3.162683 roc= 0.528672 average_precision 0.520919\n","Epoch :  128 loss= 0.749708 time= 3.179251 roc= 0.508211 average_precision 0.505688\n","Epoch :  129 loss= 0.746620 time= 3.230362 roc= 0.525344 average_precision 0.520096\n","Epoch :  130 loss= 0.747159 time= 3.188428 roc= 0.519162 average_precision 0.515954\n","Epoch :  131 loss= 0.746918 time= 3.170012 roc= 0.511348 average_precision 0.506746\n","Epoch :  132 loss= 0.743933 time= 3.155916 roc= 0.515978 average_precision 0.509829\n","Epoch :  133 loss= 0.747857 time= 3.193430 roc= 0.509240 average_precision 0.510805\n","Epoch :  134 loss= 0.742165 time= 3.175054 roc= 0.504942 average_precision 0.504687\n","Epoch :  135 loss= 0.747516 time= 3.163666 roc= 0.508148 average_precision 0.505609\n","Epoch :  136 loss= 0.747511 time= 3.156481 roc= 0.526666 average_precision 0.519071\n","Epoch :  137 loss= 0.743776 time= 3.181093 roc= 0.521743 average_precision 0.519291\n","Epoch :  138 loss= 0.742509 time= 3.164901 roc= 0.526118 average_precision 0.523329\n","Epoch :  139 loss= 0.741018 time= 3.169963 roc= 0.514269 average_precision 0.505768\n","Epoch :  140 loss= 0.740582 time= 3.168443 roc= 0.525222 average_precision 0.518812\n","\n"," Test ROC score: 0.524140    Test Precision score : 0.515898 \n","\n","Epoch :  141 loss= 0.738438 time= 3.176041 roc= 0.524296 average_precision 0.531373\n","Epoch :  142 loss= 0.739493 time= 3.165427 roc= 0.519151 average_precision 0.515562\n","Epoch :  143 loss= 0.736686 time= 3.169278 roc= 0.522888 average_precision 0.519203\n","Epoch :  144 loss= 0.735003 time= 3.183867 roc= 0.535250 average_precision 0.533246\n","Epoch :  145 loss= 0.733873 time= 3.171442 roc= 0.531343 average_precision 0.542767\n","Epoch :  146 loss= 0.729730 time= 3.169225 roc= 0.533869 average_precision 0.541463\n","Epoch :  147 loss= 0.733737 time= 3.174876 roc= 0.554460 average_precision 0.561420\n","Epoch :  148 loss= 0.726753 time= 3.164480 roc= 0.544554 average_precision 0.553201\n","Epoch :  149 loss= 0.730506 time= 3.176108 roc= 0.543715 average_precision 0.551296\n","Epoch :  150 loss= 0.730782 time= 3.154445 roc= 0.552562 average_precision 0.561353\n","Epoch :  151 loss= 0.729660 time= 3.171468 roc= 0.539083 average_precision 0.547770\n","Epoch :  152 loss= 0.730460 time= 3.174428 roc= 0.529854 average_precision 0.531765\n","Epoch :  153 loss= 0.728189 time= 3.170266 roc= 0.537052 average_precision 0.544444\n","Epoch :  154 loss= 0.730560 time= 3.166756 roc= 0.538372 average_precision 0.544970\n","Epoch :  155 loss= 0.730403 time= 3.175814 roc= 0.533949 average_precision 0.536347\n","Epoch :  156 loss= 0.727973 time= 3.153785 roc= 0.553245 average_precision 0.560120\n","Epoch :  157 loss= 0.728731 time= 3.172110 roc= 0.549213 average_precision 0.557785\n","Epoch :  158 loss= 0.724316 time= 3.171960 roc= 0.544962 average_precision 0.546869\n","Epoch :  159 loss= 0.725443 time= 3.186224 roc= 0.541772 average_precision 0.550490\n","Epoch :  160 loss= 0.723970 time= 3.175754 roc= 0.556465 average_precision 0.565867\n","\n"," Test ROC score: 0.556737    Test Precision score : 0.576786 \n","\n","Epoch :  161 loss= 0.719928 time= 3.169423 roc= 0.548791 average_precision 0.558623\n","Epoch :  162 loss= 0.717322 time= 3.180043 roc= 0.571336 average_precision 0.579556\n","Epoch :  163 loss= 0.715138 time= 3.177247 roc= 0.569687 average_precision 0.577701\n","Epoch :  164 loss= 0.718740 time= 3.171956 roc= 0.573668 average_precision 0.575547\n","Epoch :  165 loss= 0.716501 time= 3.184309 roc= 0.566606 average_precision 0.567912\n","Epoch :  166 loss= 0.713489 time= 3.173668 roc= 0.571734 average_precision 0.571348\n","Epoch :  167 loss= 0.715326 time= 3.143483 roc= 0.567665 average_precision 0.565266\n","Epoch :  168 loss= 0.711765 time= 3.190987 roc= 0.583617 average_precision 0.587210\n","Epoch :  169 loss= 0.712695 time= 3.138283 roc= 0.572798 average_precision 0.572270\n","Epoch :  170 loss= 0.711125 time= 3.165267 roc= 0.583485 average_precision 0.588779\n","Epoch :  171 loss= 0.714119 time= 3.184614 roc= 0.580245 average_precision 0.574009\n","Epoch :  172 loss= 0.715322 time= 3.168924 roc= 0.588184 average_precision 0.592926\n","Epoch :  173 loss= 0.712782 time= 3.149597 roc= 0.580188 average_precision 0.583530\n","Epoch :  174 loss= 0.713041 time= 3.162660 roc= 0.581409 average_precision 0.581584\n","Epoch :  175 loss= 0.712573 time= 3.210801 roc= 0.581930 average_precision 0.585358\n","Epoch :  176 loss= 0.709461 time= 3.170086 roc= 0.588589 average_precision 0.589213\n","Epoch :  177 loss= 0.709142 time= 3.187899 roc= 0.568465 average_precision 0.571139\n","Epoch :  178 loss= 0.709753 time= 3.253650 roc= 0.566312 average_precision 0.563699\n","Epoch :  179 loss= 0.710244 time= 3.180229 roc= 0.560017 average_precision 0.555556\n","Epoch :  180 loss= 0.710393 time= 3.174582 roc= 0.588439 average_precision 0.594299\n","\n"," Test ROC score: 0.593614    Test Precision score : 0.607980 \n","\n","Epoch :  181 loss= 0.709492 time= 3.185789 roc= 0.602791 average_precision 0.602799\n","Epoch :  182 loss= 0.705565 time= 3.178441 roc= 0.597158 average_precision 0.596739\n","Epoch :  183 loss= 0.705000 time= 3.164186 roc= 0.588992 average_precision 0.590296\n","Epoch :  184 loss= 0.704236 time= 3.157039 roc= 0.582512 average_precision 0.581376\n","Epoch :  185 loss= 0.703394 time= 3.175969 roc= 0.601790 average_precision 0.604169\n","Epoch :  186 loss= 0.702338 time= 3.179145 roc= 0.590631 average_precision 0.590891\n","Epoch :  187 loss= 0.701945 time= 3.195184 roc= 0.587641 average_precision 0.580541\n","Epoch :  188 loss= 0.703090 time= 3.190715 roc= 0.594775 average_precision 0.595849\n","Epoch :  189 loss= 0.699974 time= 3.176121 roc= 0.601889 average_precision 0.599145\n","Epoch :  190 loss= 0.702613 time= 3.158066 roc= 0.591679 average_precision 0.592901\n","Epoch :  191 loss= 0.700308 time= 3.164811 roc= 0.609075 average_precision 0.605012\n","Epoch :  192 loss= 0.704319 time= 3.165265 roc= 0.591377 average_precision 0.591165\n","Epoch :  193 loss= 0.699943 time= 3.183423 roc= 0.593513 average_precision 0.591700\n","Epoch :  194 loss= 0.701071 time= 3.174418 roc= 0.592443 average_precision 0.595227\n","Epoch :  195 loss= 0.701285 time= 3.187236 roc= 0.599217 average_precision 0.593691\n","Epoch :  196 loss= 0.702184 time= 3.148917 roc= 0.606099 average_precision 0.600897\n","Epoch :  197 loss= 0.702606 time= 3.168564 roc= 0.596589 average_precision 0.590071\n","Epoch :  198 loss= 0.701803 time= 3.159614 roc= 0.560610 average_precision 0.549901\n","Epoch :  199 loss= 0.698207 time= 3.175673 roc= 0.605685 average_precision 0.595913\n","Epoch :  200 loss= 0.704211 time= 3.175524 roc= 0.601464 average_precision 0.595920\n","\n"," Test ROC score: 0.620079    Test Precision score : 0.631887 \n","\n","Epoch :  201 loss= 0.704412 time= 3.177240 roc= 0.617531 average_precision 0.605455\n","Epoch :  202 loss= 0.702994 time= 3.181719 roc= 0.590864 average_precision 0.583768\n","Epoch :  203 loss= 0.703218 time= 3.188865 roc= 0.615202 average_precision 0.605224\n","Epoch :  204 loss= 0.697098 time= 3.216824 roc= 0.609535 average_precision 0.602235\n","Epoch :  205 loss= 0.698589 time= 3.206243 roc= 0.614542 average_precision 0.604912\n","Epoch :  206 loss= 0.697428 time= 3.197749 roc= 0.609967 average_precision 0.600573\n","Epoch :  207 loss= 0.698917 time= 3.159541 roc= 0.624915 average_precision 0.619081\n","Epoch :  208 loss= 0.698961 time= 3.154536 roc= 0.613494 average_precision 0.603774\n","Epoch :  209 loss= 0.694064 time= 3.179203 roc= 0.598879 average_precision 0.584212\n","Epoch :  210 loss= 0.699574 time= 3.185028 roc= 0.615824 average_precision 0.609273\n","Epoch :  211 loss= 0.700262 time= 3.181953 roc= 0.621830 average_precision 0.611062\n","Epoch :  212 loss= 0.697251 time= 3.167338 roc= 0.617452 average_precision 0.607097\n","Epoch :  213 loss= 0.698210 time= 3.157796 roc= 0.607368 average_precision 0.596574\n","Epoch :  214 loss= 0.696634 time= 3.169360 roc= 0.611621 average_precision 0.604044\n","Epoch :  215 loss= 0.698955 time= 3.176246 roc= 0.604791 average_precision 0.596465\n","Epoch :  216 loss= 0.696782 time= 3.162988 roc= 0.597398 average_precision 0.589689\n","Epoch :  217 loss= 0.698951 time= 3.151226 roc= 0.615728 average_precision 0.607188\n","Epoch :  218 loss= 0.697508 time= 3.173861 roc= 0.619380 average_precision 0.610833\n","Epoch :  219 loss= 0.695302 time= 3.147637 roc= 0.619678 average_precision 0.607976\n"]}],"source":["if torch.cuda.is_available():\n","  device='cuda'\n","else:\n","  device='cpu'\n","\n","import wandb\n","\n","wandb.config = {\n","  \"learning_rate\": 0.005,\n","  \"epochs\": 2000,\n","  \"u_dim\" : 32,\n","  \"latent_dim\" : 32,\n","  \"batch_size\": 30,\n","  \"K\" : 15,\n","  \"J\" : 15, \n","  \"WU\" : 200,\n","  \"noise_dim\" : 64,\n","  \"pos_enc_dim\" : 4\n","}\n","\n","wandb.init(project=\"SIG-VAE-GIN-and-fMRI\", entity=\"ytrewq271828\", config=config)\n","\n","laplacian_positional_encoding_dim=4\n","graph_processed, adj, adj_train, adj_validation, adj_test, featureMatrix, train_graph, train_pos, validation_pos, test_pos, train_neg, validation_neg, test_neg=preprocess(graph, laplacian_positional_encoding_dim)\n","adj_label=adj_train+torch.eye(adj_train.shape[0])\n","adj_label=torch.FloatTensor(adj_label)\n","\n","#print((adj.transpose(0,1)==adj).all())\n","##print((adj_train.transpose(0,1)==adj_train).all())\n","#print((adj_test.transpose(0,1)==adj_test).all())\n","#print((adj_validation.transpose(0,1)==adj_validation).all())\n","adj=torch.Tensor(adj).to(device)\n","adj_test=torch.Tensor(adj_test).to(device)\n","featureMatrix=torch.cuda.FloatTensor(featureMatrix)\n","adj_train=torch.Tensor(adj_train).to(device)\n","train_graph=train_graph.to(device)\n","#test_graph=test_graph.to(device)\n","#validation_graph=validation_graph.to(device)\n","graph_processed=graph_processed.to(device)\n","N=adj.shape[0]\n","weight=torch.tensor([float(N * N - adj.sum()) / adj.sum()]).to(device)\n","norm=N*N/float((N*N-adj.sum())*2)\n","\n","pos_array_train=torch.cuda.LongTensor(train_pos).t() #(2, #positive edges)\n","neg_array_train=torch.cuda.LongTensor(train_neg).t() #(2, #negative edges)\n","pos_array_test=torch.cuda.LongTensor(test_pos).t()\n","neg_array_test=torch.cuda.LongTensor(test_neg).t()\n","pos_array_validation=torch.cuda.LongTensor(validation_pos).t()\n","neg_array_validation=torch.cuda.LongTensor(validation_neg).t()\n","#print(torch.count_nonzero(adj_train))\n","#print(torch.count_nonzero(adj_test))\n","#print(adj_test.shape)\n","#print(pos_array_train)?\n","print(pos_array_validation.shape)\n","print(neg_array_validation.shape)\n","print(\"%%%%%%%%%%%%%%%%%%%%%55\")\n","print(train_graph.number_of_nodes())\n","torch.autograd.set_detect_anomaly(False)\n","\n","model=SIGVAE_GIN_Transformer(Lu=1, \n","                Lmu=1, \n","                Lsigma=1, \n","                input_dim=featureMatrix.shape[2], \n","                output_dim_u=[32], \n","                output_dim_mu=[32], \n","                output_dim_sigma=[32],\n","                K=15,\n","                J=15,\n","                lap_pos_enc_dim=4,\n","                device=device,\n","                noise_dim=64,\n","                decoder_type=\"bp\",\n","                activation=torch.nn.functional.relu,\n","                dropout=0)\n","K=15\n","J=15\n","batch_graph=[]\n","for i in range((K+J)):\n","  train_graph_copy=copy.deepcopy(train_graph)\n","  batch_graph.append(train_graph_copy)\n","#batch_graph=[train_graph]*(K+J)\n","dropout=0\n","optimizer=torch.optim.Adam(model.parameters(), lr=0.005)\n","scheduler=optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0, verbose=False)\n","epoch=2000\n","loss_accumulate=0\n","max_test_auc=0\n","max_test_ap=0\n","for epc in range(epoch):\n","    t=time.time()\n","    model.train()\n","    \n","    latent_representation, generated_prob, loss_train, z_proc, rk=step(model, adj_train, adj_label, featureMatrix, train_graph, batch_graph, epc, K, J, weight, norm, dropout, optimizer=optimizer, scheduler=scheduler, device=device)\n","    #loss_accumulate+=loss_train\n","    \n","    #print(z_proc)    \n","    #print(z_proc.shape)\n","    #z_proc=z_proc.detach().cpu().numpy()\n","    \n","    #roc, avg_precision, precision, recall, fpr, tpr=get_auc(z_proc, pos_array_validation, neg_array_validation, decoder_type=\"bp\")\n","    roc, avg_precision=get_auc(z_proc, adj, rk,  pos_array_validation, neg_array_validation, decoder_type=\"bp\")\n","    \n","    #roc, acc, prc, rcl=get_auc(z_proc, pos_array_train, neg_array_train, decoder_type=\"bp\")\n","    #print(loss_train.item())\n","    #print(roc)\n","    print(\"Epoch : \", '%d' %(epc+1), \"loss=\", \"%f\" %(loss_train.item()),\n","          \"time=\", \"%f\" %(time.time()-t), \"roc=\", \"%f\" %(roc), \"average_precision\", \"%f\" %(avg_precision),\n","          #\"precision\", \"%f\" %(precision), \"recall\", \"%f\" %(recall),\n","          #\"false positive rate\", \"%f\" %(fpr), \"true positive rate\", \"%f\" %(tpr))\n","    )\n","    #pyplot.plot(fpr, recall, marker='.', label='roc-auc')\n","    \n","    \n","    wandb.log({\"loss_train\": loss_train})\n","    wandb.log({\"roc-auc\": roc})\n","    wandb.log({\"average_precision\": avg_precision})\n","    wandb.watch(model)\n","    \n","    '''\n","    wandb.log({\"recall_train\" : recall})\n","    wandb.log({\"fpr_train\" : fpr})\n","    wandb.watch(model)\n","    '''\n","    del latent_representation\n","    del generated_prob\n","    del z_proc\n","    del roc\n","    del rk\n","    del avg_precision\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    if (epc+1) % 20 == 0:\n","          with torch.no_grad():\n","            model.eval()\n","            #generated_prob, mu, sigma, latent_representation, z_proc, epsilon=model(adj_test, featureMatrix, test_graph)\n","            latent_representation, generated_prob, loss_test, z_proc, rk=step(model, adj_train, adj_label, featureMatrix, train_graph, batch_graph, epc, K, J, weight, norm, dropout, optimizer=None, scheduler=None, device=device)\n","\n","            #z_proc = z_proc.detach().cpu().numpy()\n","            roc, avg_pre= get_auc(z_proc, adj, rk, pos_array_test, neg_array_test, decoder_type=\"bp\")\n","            if roc>max_test_auc:\n","              max_test_auc=roc\n","            if avg_pre>max_test_ap:\n","              max_test_ap=avg_pre\n","            rslt = \"Test ROC score: %f\" %(roc)\n","            rslt2=\"Test Precision score : %f\" %(avg_pre)\n","            print(\"\\n\", rslt, \"  \", rslt2, \"\\n\")\n","                     \n","            wandb.log({\"loss_test\": loss_test})\n","            wandb.log({\"roc-auc_test\" : roc})\n","            wandb.log({\"ap_test\" : avg_pre})\n","            wandb.watch(model)\n","            \n","\n","            del latent_representation\n","            del generated_prob\n","            del z_proc\n","            del roc\n","            del rk\n","            #del avg_precision\n","            torch.cuda.empty_cache()\n","            gc.collect()\n","            \n","#pyplot.show()\n","print(\"Max ROC-AUC score : %f\" %(max_test_auc))\n","print(\"Max AP score : %f\" %(max_test_ap))\n","    #latent_representation, generated_prob, loss_train=step(model, adj_train, epoch, optimizer )"]},{"cell_type":"code","source":[""],"metadata":{"id":"s86NzOjLbwS_"},"execution_count":null,"outputs":[]}]}