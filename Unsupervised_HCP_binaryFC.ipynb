{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":108761,"status":"ok","timestamp":1656493278311,"user":{"displayName":"김준엽","userId":"13244491849873010810"},"user_tz":-540},"id":"HYuDMzcdvBMm","outputId":"2427f667-2582-4c6d-95ea-565dedecbfe9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://data.dgl.ai/wheels/repo.html\n","Collecting dgl-cu113\n","  Downloading https://data.dgl.ai/wheels/dgl_cu113-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (220.6 MB)\n","\u001b[K     |████████████████████████████████| 220.6 MB 36 kB/s \n","\u001b[?25hCollecting dglgo\n","  Downloading dglgo-0.0.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 6.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu113) (1.21.6)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu113) (2.23.0)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl-cu113) (2.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from dgl-cu113) (4.64.0)\n","Collecting psutil>=5.8.0\n","  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n","\u001b[K     |████████████████████████████████| 281 kB 91.7 MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu113) (1.4.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu113) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu113) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu113) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu113) (2022.6.15)\n","Collecting autopep8>=1.6.0\n","  Downloading autopep8-1.6.0-py2.py3-none-any.whl (45 kB)\n","\u001b[K     |████████████████████████████████| 45 kB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from dglgo) (0.4.1)\n","Collecting pydantic>=1.9.0\n","  Downloading pydantic-1.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n","\u001b[K     |████████████████████████████████| 11.1 MB 68.6 MB/s \n","\u001b[?25hCollecting isort>=5.10.1\n","  Downloading isort-5.10.1-py3-none-any.whl (103 kB)\n","\u001b[K     |████████████████████████████████| 103 kB 85.0 MB/s \n","\u001b[?25hCollecting ruamel.yaml>=0.17.20\n","  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n","\u001b[K     |████████████████████████████████| 109 kB 84.4 MB/s \n","\u001b[?25hCollecting PyYAML>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 87.0 MB/s \n","\u001b[?25hCollecting numpydoc>=1.1.0\n","  Downloading numpydoc-1.4.0-py3-none-any.whl (51 kB)\n","\u001b[K     |████████████████████████████████| 51 kB 781 kB/s \n","\u001b[?25hCollecting pycodestyle>=2.8.0\n","  Downloading pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)\n","\u001b[K     |████████████████████████████████| 42 kB 1.1 MB/s \n","\u001b[?25hCollecting toml\n","  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.7/dist-packages (from numpydoc>=1.1.0->dglgo) (2.11.3)\n","Collecting sphinx>=3.0\n","  Downloading Sphinx-5.0.2-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 56.7 MB/s \n","\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic>=1.9.0->dglgo) (4.1.1)\n","Collecting ruamel.yaml.clib>=0.2.6\n","  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n","\u001b[K     |████████████████████████████████| 546 kB 32.8 MB/s \n","\u001b[?25hRequirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2.6.1)\n","Collecting sphinxcontrib-qthelp\n","  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 10.3 MB/s \n","\u001b[?25hRequirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.3.0)\n","Collecting sphinxcontrib-jsmath\n","  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (21.3)\n","Collecting sphinxcontrib-htmlhelp>=2.0.0\n","  Downloading sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl (100 kB)\n","\u001b[K     |████████████████████████████████| 100 kB 12.9 MB/s \n","\u001b[?25hRequirement already satisfied: docutils<0.19,>=0.14 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (0.17.1)\n","Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2.10.2)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (4.11.4)\n","Collecting sphinxcontrib-devhelp\n","  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n","\u001b[K     |████████████████████████████████| 84 kB 4.4 MB/s \n","\u001b[?25hRequirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.1.5)\n","Collecting sphinxcontrib-applehelp\n","  Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n","\u001b[K     |████████████████████████████████| 121 kB 102.4 MB/s \n","\u001b[?25hRequirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2.2.0)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (0.7.12)\n","Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel>=1.3->sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2022.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->sphinx>=3.0->numpydoc>=1.1.0->dglgo) (3.8.0)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer>=0.4.0->dglgo) (7.1.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->sphinx>=3.0->numpydoc>=1.1.0->dglgo) (3.0.9)\n","Installing collected packages: sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, toml, sphinx, ruamel.yaml.clib, pycodestyle, ruamel.yaml, PyYAML, pydantic, psutil, numpydoc, isort, autopep8, dglgo, dgl-cu113\n","  Attempting uninstall: sphinx\n","    Found existing installation: Sphinx 1.8.6\n","    Uninstalling Sphinx-1.8.6:\n","      Successfully uninstalled Sphinx-1.8.6\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 1.8.2\n","    Uninstalling pydantic-1.8.2:\n","      Successfully uninstalled pydantic-1.8.2\n","  Attempting uninstall: psutil\n","    Found existing installation: psutil 5.4.8\n","    Uninstalling psutil-5.4.8:\n","      Successfully uninstalled psutil-5.4.8\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","thinc 8.0.17 requires pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4, but you have pydantic 1.9.1 which is incompatible.\n","spacy 3.3.1 requires pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4, but you have pydantic 1.9.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed PyYAML-6.0 autopep8-1.6.0 dgl-cu113-0.8.2 dglgo-0.0.1 isort-5.10.1 numpydoc-1.4.0 psutil-5.9.1 pycodestyle-2.8.0 pydantic-1.9.1 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.6 sphinx-5.0.2 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 toml-0.10.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["psutil","sphinxcontrib"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch_lightning\n","  Downloading pytorch_lightning-1.6.4-py3-none-any.whl (585 kB)\n","\u001b[K     |████████████████████████████████| 585 kB 10.6 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.11.0+cu113)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.21.6)\n","Collecting torchmetrics>=0.4.1\n","  Downloading torchmetrics-0.9.1-py3-none-any.whl (419 kB)\n","\u001b[K     |████████████████████████████████| 419 kB 78.7 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.1.1)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (6.0)\n","Collecting pyDeprecate>=0.3.1\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.64.0)\n","Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (3.17.3)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.8.0)\n","Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 91.5 MB/s \n","\u001b[?25hCollecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 5.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1->pytorch_lightning) (1.15.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.46.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.1.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (57.4.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.7)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.11.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.2.0)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 74.0 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.4.0)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 86.0 MB/s \n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 3.3 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.0.12)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, torchmetrics, pyDeprecate, pytorch-lightning\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.5.0 multidict-6.0.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.4 torchmetrics-0.9.1 yarl-1.7.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.12.19-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 18.6 MB/s \n","\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 74.6 MB/s \n","\u001b[?25hCollecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.9.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Collecting setproctitle\n","  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n","Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.6.0-py2.py3-none-any.whl (145 kB)\n","\u001b[K     |████████████████████████████████| 145 kB 76.7 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=c7a631ae6566e3cdf4af82c156819b251976defd4cc419788999eff58af06a2c\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n","Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.6.0 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 wandb-0.12.19\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install dgl-cu113 dglgo -f https://data.dgl.ai/wheels/repo.html\n","!pip install pytorch_lightning\n","!pip install wandb\n","#!wandb login"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":615,"status":"ok","timestamp":1656493284837,"user":{"displayName":"김준엽","userId":"13244491849873010810"},"user_tz":-540},"id":"Ttry1fIBKbfS","outputId":"3d110631-3aaf-4144-f0cc-47cb2c6f5ed3"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}],"source":["%ls\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9700,"status":"ok","timestamp":1656493296576,"user":{"displayName":"김준엽","userId":"13244491849873010810"},"user_tz":-540},"id":"XUWkpYeBTsK4","outputId":"62488b16-c465-47dc-afbe-28c5fd719dbc"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive\n","/content/drive/MyDrive\n","/content/drive/MyDrive/SIG-VAE-GIN-and-fMRI\n","/content/drive/MyDrive/SIG-VAE-GIN-and-fMRI/SIG-VAE-GIN-and-fMRI\n"]},{"output_type":"stream","name":"stderr","text":["DGL backend not selected or invalid.  Assuming PyTorch for now.\n"]},{"output_type":"stream","name":"stdout","text":["Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"]}],"source":["\n","%cd drive\n","%cd MyDrive\n","%cd SIG-VAE-GIN-and-fMRI\n","%cd SIG-VAE-GIN-and-fMRI\n","\n","from sigvaemodel_transformer import *\n","from loss import *\n","from Dataset import *\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1656493299081,"user":{"displayName":"김준엽","userId":"13244491849873010810"},"user_tz":-540},"id":"GzE106uMKf7o"},"outputs":[],"source":["%reload_ext autoreload\n","from sigvaemodel_transformer import *\n","from loss import loss as loss_function\n","from Dataset import *\n","#from graph_transformer_edge_layer import *\n","from graph_transformer_layer import *\n","from mlp_readout_layer import *\n","#from loss import get_rec"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2302,"status":"ok","timestamp":1656493332509,"user":{"displayName":"김준엽","userId":"13244491849873010810"},"user_tz":-540},"id":"T5FmKW1Z726f"},"outputs":[],"source":["import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","import dgl.data\n","import copy\n","import networkx as nx\n","import scipy.sparse as sp\n","from sklearn.metrics import average_precision_score, roc_curve, precision_recall_curve, roc_auc_score, mean_squared_error\n","import sigvaemodel_transformer\n","import loss\n","import Dataset\n","import time\n","import wandb\n","import torch.optim as optim\n","import gc\n","import random\n","from pytorch_lightning.loggers import WandbLogger\n","from tqdm import tqdm\n","#from torchviz import make_dot\n","device=torch.device('cuda')\n","#fMRI_load=torch.load('HCP_REST1_LR_schaefer400_sub19.pth', map_location=device)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"elapsed":483,"status":"ok","timestamp":1656493334631,"user":{"displayName":"김준엽","userId":"13244491849873010810"},"user_tz":-540},"id":"sLgveehaJT82","outputId":"dd55e257-ec07-45cd-8870-18a2da2d9f36"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n#os.chdir(\\'..\\')\\n#%cd SIG-VAE-GIN-and-fMRI\\n!pwd\\n#print(os.listdir(\\'/content/drive/MyDrive/SIG-VAE-GIN-and-fMRI/SIG-VAE-GIN-and-fMRI/fMRI\\'))\\n#prepare_HCPRest_timeseries(atlas=\\'schaefer400_sub19\\')\\ndataset=DatasetHCPRest(atlas=\\'schaefer400_sub19\\', target_feature=\\'Gender\\', k_fold=None, session=\\'REST1\\', phase_encoding=\\'LR\\')\\ndataloader=DataLoader(dataset, batch_size=1, shuffle=False)\\nbatch_iterator=iter(dataloader)\\ntest=next(batch_iterator)\\nprint(\"################\")\\nprint(test)\\nprint(len(test))\\nprint(len(test.values()))\\nprint((test[\\'id\\']))\\nprint(test[\\'timeseries\\'].shape)\\nprint(len(test[\\'label\\']))\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}],"source":["'''\n","#os.chdir('..')\n","#%cd SIG-VAE-GIN-and-fMRI\n","!pwd\n","#print(os.listdir('/content/drive/MyDrive/SIG-VAE-GIN-and-fMRI/SIG-VAE-GIN-and-fMRI/fMRI'))\n","#prepare_HCPRest_timeseries(atlas='schaefer400_sub19')\n","dataset=DatasetHCPRest(atlas='schaefer400_sub19', target_feature='Gender', k_fold=None, session='REST1', phase_encoding='LR')\n","dataloader=DataLoader(dataset, batch_size=1, shuffle=False)\n","batch_iterator=iter(dataloader)\n","test=next(batch_iterator)\n","print(\"################\")\n","print(test)\n","print(len(test))\n","print(len(test.values()))\n","print((test['id']))\n","print(test['timeseries'].shape)\n","print(len(test['label']))\n","'''"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1656493336236,"user":{"displayName":"김준엽","userId":"13244491849873010810"},"user_tz":-540},"id":"nZteNAu3726m"},"outputs":[],"source":["def edges_to_lists(headMatrix, tailMatrix):\n","    results=[]\n","    assert len(headMatrix)==len(tailMatrix)\n","    hlength=len(headMatrix)\n","    for i in range(hlength):\n","        results.append([headMatrix[i], tailMatrix[i]])\n","    return results"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1656493338009,"user":{"displayName":"김준엽","userId":"13244491849873010810"},"user_tz":-540},"id":"sPSN87qDNFu9"},"outputs":[],"source":["def laplacian_positional_encoding(g, pos_enc_dim):\n","    \"\"\"\n","        Graph positional encoding v/ Laplacian eigenvectors\n","    \"\"\"\n","\n","    # Laplacian\n","    A = g.adjacency_matrix_scipy(return_edge_ids=False).astype(float)\n","    N = sp.diags(dgl.backend.asnumpy(g.in_degrees()).clip(1) ** -0.5, dtype=float)\n","    L = sp.eye(g.number_of_nodes()) - N * A * N\n","\n","    # Eigenvectors with scipy\n","    #EigVal, EigVec = sp.linalg.eigs(L, k=pos_enc_dim+1, which='SR')\n","    EigVal, EigVec = sp.linalg.eigs(L, k=pos_enc_dim+1, which='SR', tol=1e-2) # for 40 PEs\n","    EigVec = EigVec[:, EigVal.argsort()] # increasing order\n","    g.ndata['lap_pos_enc'] = torch.from_numpy(EigVec[:,1:pos_enc_dim+1]).float() \n","\n","    return g"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1656493339058,"user":{"displayName":"김준엽","userId":"13244491849873010810"},"user_tz":-540},"id":"Xz2zVKFb726o"},"outputs":[],"source":["def step(model, adj, adj_label, feat, input_graph, batch_graph, epoch, K, J, weight, norm, dropout, optimizer, scheduler, device):\n","  #global loss\n","    if optimizer is None:\n","        with torch.no_grad():\n","          model.eval()\n","        WU=1\n","    else:\n","        model.train()\n","        optimizer.zero_grad()\n","        #WU=torch.min(torch.Tensor([epoch/200., 1.]))\n","        WU=1\n","        \n","    generated_prob, mu, sigma, latent_representation, Z, epsilon, rk=model.forward(adj.to(device), feat.to(device), input_graph, batch_graph)\n","    loss=loss_function(generated_prob, adj_label, mu, sigma, Z, epsilon, latent_representation, K, J, WU, norm, weight, dropout, device=device)\n","    \n","    \n","    if optimizer is not None:\n","        loss.backward()\n","        optimizer.step()\n","        if scheduler is not None:\n","          scheduler.step()\n","    del mu\n","    del sigma\n","    del epsilon\n","    return latent_representation, generated_prob, loss, Z, rk"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1656493340757,"user":{"displayName":"김준엽","userId":"13244491849873010810"},"user_tz":-540},"id":"aba_UkNc726q"},"outputs":[],"source":["def get_auc(embedding, adj_orig, rk, decoder_type='bp'):\n","\n","    J=embedding.shape[0]\n","    rk_expand=torch.tile(torch.diag(rk), (J, 1, 1))\n","    X=torch.transpose(embedding, 1, 2)\n","    X=torch.bmm(rk_expand, X)\n","    X=torch.bmm(embedding, X)\n","    X=torch.clamp(X, min=float('-inf'), max=10)\n","    \n","    adj_rec=1-torch.exp(-torch.exp(X)).detach().cpu().numpy()\n","    adj_orig_flatten=torch.flatten(adj_orig).detach().cpu().numpy() #flatten to calculate AUROC\n","    roc=torch.Tensor([roc_auc_score(adj_orig_flatten, adj_recon.flatten()) for adj_recon in np.vsplit(adj_rec, embedding.shape[0])]).mean()\n","    avg_precision=torch.Tensor([average_precision_score(adj_orig_flatten, adj_recon.flatten()) for adj_recon in np.vsplit(adj_rec, embedding.shape[0])]).mean()\n","    \n","    \n","    del adj_rec\n","    del adj_orig_flatten\n","    del X\n","    del rk_expand\n","\n","    return roc, avg_precision #, precision_mean, recall_mean, fpr_mean, tpr_mean"]},{"cell_type":"code","source":["def get_mse(embedding, adj_orig, rk, decoder_type='bp'):\n","    \n","    J=embedding.shape[0]\n","    rk_expand=torch.tile(torch.diag(rk), (J, 1, 1))\n","    X=torch.transpose(embedding, 1, 2)\n","    X=torch.bmm(rk_expand, X)\n","    X=torch.bmm(embedding, X)\n","    X=torch.clamp(X, min=float('-inf'), max=10)\n","\n","    adj_rec=1-torch.exp(-torch.exp(X)).detach().cpu().numpy()\n","    adj_orig_flatten=torch.flatten(adj_orig).detach().cpu().numpy() #flatten to calculate AUROC\n","    mse=torch.Tensor([mean_squared_error(adj_orig_flatten, adj_recon.flatten()) for adj_recon in np.vsplit(adj_rec, embedding.shape[0])]).mean()\n","\n","    del adj_rec\n","    del adj_orig_flatten\n","    del X\n","    del rk_expand\n","\n","    return mse"],"metadata":{"id":"8F8F2PDAGKwm","executionInfo":{"status":"ok","timestamp":1656493343051,"user_tz":-540,"elapsed":3,"user":{"displayName":"김준엽","userId":"13244491849873010810"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1656493344847,"user":{"displayName":"김준엽","userId":"13244491849873010810"},"user_tz":-540},"id":"KtRxu_CFtuIX"},"outputs":[],"source":["def corrcoef(x):\n","    #from STAGIN\n","    mean_x = torch.mean(x, 1, keepdim=True)\n","    xm = x.sub(mean_x.expand_as(x))\n","    c = xm.mm(xm.t())\n","    c = c / (x.size(1) - 1)\n","    d = torch.diag(c)\n","    stddev = torch.pow(d, 0.5)\n","    c = c.div(stddev.expand_as(c))\n","    c = c.div(stddev.expand_as(c).t())\n","    c = torch.clamp(c, -1.0, 1.0)\n","    return c"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1656493346513,"user":{"displayName":"김준엽","userId":"13244491849873010810"},"user_tz":-540},"id":"9LaTs3myxy95"},"outputs":[],"source":["def generateFC(argTensor, self_loop=True):\n","  #shape of argTensor : (number of ROIs=419, number of timepoints=1200)\n","  fc=corrcoef(argTensor)\n","  if not self_loop:\n","      fc-=torch.eye(fc.shape[0])\n","  fc_matrix=fc\n","  #print(fc_matrix.shape)\n","  return fc_matrix"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1656493348596,"user":{"displayName":"김준엽","userId":"13244491849873010810"},"user_tz":-540},"id":"uLSRUuAuwVv6"},"outputs":[],"source":["def graphFC(n, pos_enc_dim, quantile, fc_matrix):\n","    '''\n","    using weighted FC as adjacency matrix\n","    '''\n","    threshold=torch.quantile(fc_matrix, quantile, dim=None)\n","    adj=torch.where(fc_matrix>=threshold, 1, 0)\n","    #adj=fc_matrix\n","    adj_u, adj_v=torch.where(adj!=0)\n","    #adj_u=adj\n","    #adj_v=adj\n","    fc_graph=dgl.graph((torch.hstack((adj_u, adj_v)), torch.hstack((adj_v, adj_u))), num_nodes=n)\n","    featureMatrix=torch.eye(n)\n","    fc_graph.ndata['feat']=featureMatrix\n","    fc_graph.edata['FC']=torch.ones(torch.count_nonzero(adj)*2)\n","    fc_graph=laplacian_positional_encoding(fc_graph, pos_enc_dim)\n","    featureMatrix3D=featureMatrix.unsqueeze(0)\n","    return fc_graph, adj, featureMatrix3D"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1656493350076,"user":{"displayName":"김준엽","userId":"13244491849873010810"},"user_tz":-540},"id":"HykOQTzzL8Op"},"outputs":[],"source":["def train(num_epochs, target_feature, k_fold, dataset, targetdir, seed, quantile, learning_rate, num_ROI=419, graphbatch_size=25, minibatch_size=1):\n","    \n","    # make directories\n","    os.makedirs(os.path.join(targetdir, 'model'), exist_ok=True)\n","    os.makedirs(os.path.join(targetdir, 'summary'), exist_ok=True)\n","    \n","    experiment_name=f'{num_epochs}_{target_feature}_{quantile}_{learning_rate}_train'\n","    # set seed and device\n","    torch.manual_seed(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    if torch.cuda.is_available():\n","        device = torch.device(\"cuda\")\n","        torch.cuda.manual_seed_all(seed)\n","    else:\n","        device = torch.device(\"cpu\")\n","\n","    # define dataset\n","    if dataset=='rest': dataset = DatasetHCPRest(atlas='schaefer400_sub19', target_feature=target_feature, k_fold=k_fold, session='REST1', phase_encoding='LR')\n","    else: raise\n","    dataloader = DataLoader(dataset, batch_size=minibatch_size, shuffle=False, num_workers=4, pin_memory=True)\n","\n","    # resume checkpoint if file exists\n","    if os.path.isfile(os.path.join(targetdir, 'checkpoint.pth')):\n","        print('resuming checkpoint experiment')\n","        checkpoint = torch.load(os.path.join(targetdir, 'checkpoint.pth'), map_location=device)\n","    else:\n","        checkpoint = {\n","            'fold': 0,\n","            'epoch': 0,\n","            'model': None,\n","            'optimizer': None,\n","            'scheduler': None}\n","\n","    featureMatrix=(torch.eye(num_ROI)).unsqueeze(0)\n","    print(\"$$$$\")\n","    print(featureMatrix.shape)\n","    # start experiment\n","    for k in range(checkpoint['fold'], k_fold):\n","        # make directories per fold\n","        os.makedirs(os.path.join(targetdir, 'model', str(k)), exist_ok=True)\n","\n","        # set dataloader\n","        dataset.set_fold(k, train=True)\n","\n","        # define model\n","        model=SIGVAE_GIN_Transformer(\n","                Lu=1, \n","                Lmu=1, \n","                Lsigma=1, \n","                input_dim=num_ROI, #number of ROIs in .pth file\n","                output_dim_u=[32], \n","                output_dim_mu=[32], \n","                output_dim_sigma=[32],\n","                K=5,\n","                J=8,\n","                lap_pos_enc_dim=4,\n","                device=device,\n","                noise_dim=64,\n","                decoder_type=\"bp\",\n","                activation=torch.nn.functional.relu,\n","                dropout=0)\n","        model.to(device)\n","        if checkpoint['model'] is not None: model.load_state_dict(checkpoint['model'])\n","\n","        # define optimizer and learning rate scheduler\n","        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","        scheduler=optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20, eta_min=0, verbose=False)\n","        if checkpoint['optimizer'] is not None: optimizer.load_state_dict(checkpoint['optimizer'])\n","        if checkpoint['scheduler'] is not None: scheduler.load_state_dict(checkpoint['scheduler'])\n","        '''\n","        # define logging objects\n","        summary_writer = SummaryWriter(os.path.join(argv.targetdir, 'summary', str(k), 'train'), )\n","        summary_writer_val = SummaryWriter(os.path.join(argv.targetdir, 'summary', str(k), 'val'), )\n","        logger = util.logger.LoggerSTAGIN(argv.k_fold, dataset.num_classes)\n","        '''\n","        '''\n","        wandb.init(project=\"SIG-VAE-GIN-and-fMRI\", entity=\"ytrewq271828\")\n","        wandb.config = {\n","            \"learning_rate\": learning_rate,\n","            \"epochs\": num_epochs,\n","            \"graph_batch_size\": graphbatch_size,\n","            }\n","        wandb.run.name = f\"{experiment_name}_{wandb.run.id}\"\n","        wandb.run.save()\n","        logger = WandbLogger(project=\"SIG-VAE-GIN-and-fMRI\", name=experiment_name)\n","        ''' \n","        # start training\n","        for epoch in range(checkpoint['epoch'], num_epochs):\n","            dataset.set_fold(k, train=True)\n","            loss_accumulate = 0.0\n","            for i, x in enumerate(tqdm(dataloader, ncols=60, desc=f'k:{k} e:{epoch}')):\n","                t=time.time()\n","                # process input data\n","                mean_timeseries=x['timeseries'].squeeze(0)\n","                N=mean_timeseries.shape[0]\n","                fc_matrix=generateFC(mean_timeseries, self_loop=True)\n","                graph, adj, feat=graphFC(N, quantile=quantile, pos_enc_dim=4, fc_matrix=fc_matrix)\n","                graph=graph.to(device)\n","                adj_label=adj+torch.eye(N)\n","                '''\n","                dyn_a, sampling_points = util.bold.process_dynamic_fc(x['timeseries'], argv.window_size, argv.window_stride, argv.dynamic_length)\n","                sampling_endpoints = [p+argv.window_size for p in sampling_points]\n","                if i==0: dyn_v = repeat(torch.eye(dataset.num_nodes), 'n1 n2 -> b t n1 n2', t=len(sampling_points), b=argv.minibatch_size)\n","                if len(dyn_a) < argv.minibatch_size: dyn_v = dyn_v[:len(dyn_a)]\n","                t = x['timeseries'].permute(1,0,2)\n","                label = x['label']\n","                '''\n","                #N=adj.shape[0]\n","                batch_graph=[]\n","                for i in range(graphbatch_size):\n","                  train_graph_copy=copy.deepcopy(graph)\n","                  batch_graph.append(train_graph_copy)\n","                weight=torch.tensor([float(N * N - adj.sum()) / adj.sum()]).to(device)\n","                norm=N*N/float((N*N-adj.sum())*2)\n","                latent_representation, generated_prob, loss_train, z_proc, rk=step(\n","                    model=model,\n","                    adj=adj, \n","                    adj_label=adj_label, \n","                    feat=feat, \n","                    input_graph=graph, \n","                    batch_graph=batch_graph, \n","                    epoch=epoch, \n","                    K=5, \n","                    J=8,\n","                    weight=weight, \n","                    norm=norm, \n","                    dropout=0, \n","                    optimizer=optimizer, \n","                    scheduler=scheduler, \n","                    device=device)\n","                #loss_accumulate += loss.detach().cpu().numpy()\n","                loss_accumulate += loss_train\n","\n","                roc, avg_precision=get_auc(z_proc, adj, rk, decoder_type=\"bp\")\n","                #mse=get_mse(z_proc, adj, rk, decoder_type=\"bp\")\n","                print(\"\\nEpoch : \", '%d' %(epoch+1), \"fold : \", '%d' %(k), \"loss=\", \"%f\" %(loss_train.item()),\n","                      \"time=\", \"%f\" %(time.time()-t), \"roc=\", \"%f\" %(roc), \"average_precision\", \"%f\" %(avg_precision))\n","                #print(\"\\nEpoch : \", '%d' %(epoch+1), \"fold : \", '%d' %(k), \"loss=\", \"%f\" %(loss_train.item()),\n","                #      \"time=\", \"%f\" %(time.time()-t), \"mean-squared error : \", '%f' %(mse))\n","            # save checkpoint\n","            torch.save({\n","                'fold': k,\n","                'epoch': epoch+1,\n","                'model': model.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","                'scheduler': scheduler.state_dict()},\n","                os.path.join(targetdir, 'checkpoint.pth'))\n","\n","        # finalize fold\n","        torch.save(model.state_dict(), os.path.join(targetdir, 'model', str(k), 'model.pth'))\n","        checkpoint.update({'epoch': 0, 'model': None, 'optimizer': None, 'scheduler': None})\n","    '''\n","    wandb.finish()\n","    '''\n","    os.remove(os.path.join(targetdir, 'checkpoint.pth'))\n","\n"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":503,"status":"ok","timestamp":1656493351714,"user":{"displayName":"김준엽","userId":"13244491849873010810"},"user_tz":-540},"id":"dbY_Mx-0_50q"},"outputs":[],"source":["def test(num_epochs, target_feature, k_fold, dataset, targetdir, seed, quantile, learning_rate, num_ROI=419, graphbatch_size=13, minibatch_size=1):\n","    # make directories\n","    os.makedirs(os.path.join(targetdir, 'model'), exist_ok=True)\n","    os.makedirs(os.path.join(targetdir, 'summary'), exist_ok=True)\n","\n","    experiment_name=f'{num_epochs}_{target_feature}_{quantile}_{learning_rate}_test'\n","    # set seed and device\n","    torch.manual_seed(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    if torch.cuda.is_available():\n","        device = torch.device(\"cuda\")\n","        torch.cuda.manual_seed_all(seed)\n","    else:\n","        device = torch.device(\"cpu\")\n","\n","    # define dataset\n","    if dataset=='rest': dataset = DatasetHCPRest(atlas='schaefer400_sub19', target_feature=target_feature, k_fold=k_fold, session='REST1', phase_encoding='LR')\n","    else: raise\n","    dataloader = DataLoader(dataset, batch_size=minibatch_size, shuffle=False, num_workers=4, pin_memory=True)\n","\n","    featureMatrix=(torch.eye(num_ROI)).unsqueeze(0)\n","    # start experiment\n","    for k in range(k_fold):\n","        # make directories per fold\n","        os.makedirs(os.path.join(targetdir, 'model', str(k)), exist_ok=True)\n","\n","        # set dataloader\n","        dataset.set_fold(k, train=True)\n","\n","        # define model\n","        model=SIGVAE_GIN_Transformer(\n","                Lu=1, \n","                Lmu=1, \n","                Lsigma=1, \n","                input_dim=num_ROI, #number of ROIs in .pth file\n","                output_dim_u=[32], \n","                output_dim_mu=[32], \n","                output_dim_sigma=[32],\n","                K=5,\n","                J=8,\n","                lap_pos_enc_dim=4,\n","                device=device,\n","                noise_dim=64,\n","                decoder_type=\"bp\",\n","                activation=torch.nn.functional.relu,\n","                dropout=0)\n","        model.to(device)\n","        '''\n","        wandb.init(project=\"SIG-VAE-GIN-and-fMRI\", entity=\"ytrewq271828\")\n","        wandb.config = {\n","            \"learning_rate\": learning_rate,\n","            \"epochs\": num_epochs,\n","            \"graph_batch_size\": graphbatch_size,\n","            }\n","        wandb.run.name = f\"{experiment_name}_{wandb.run.id}\"\n","        wandb.run.save()\n","        logger = WandbLogger(project=\"SIG-VAE-GIN-and-fMRI\", name=experiment_name)\n","        '''\n","        # start testing\n","        dataset.set_fold(k, train=True)\n","        loss_accumulate = 0.0\n","        for i, x in enumerate(tqdm(dataloader, ncols=60, desc=f'k:{k}')):\n","          with torch.no_grad():\n","            # process input data\n","            mean_timeseries=torch.mean(x['timeseries'].squeeze(0), dim=0) #len=419\n","            N=mean_timeseries.shape[0]\n","            fc_matrix=generateFC(mean_timeseries, self_loop=True)\n","            graph, adj, feat=graphFC(N, quantile=quantile, pos_enc_dim=4, fc_matrix=fc_matrix)\n","            graph=graph.to(device)\n","            adj_label=adj+torch.eye(N)\n","           \n","\n","            batch_graph=[]\n","            for i in range(graphbatch_size):\n","              train_graph_copy=copy.deepcopy(graph)\n","              batch_graph.append(train_graph_copy)\n","            weight=torch.tensor([float(N * N - adj.sum()) / adj.sum()]).to(device)\n","            norm=N*N/float((N*N-adj.sum())*2)\n","            latent_representation, generated_prob, loss_test, z_proc, rk=step(\n","                model=model,\n","                adj=adj, \n","                adj_label=adj_label, \n","                feat=feat, \n","                input_graph=graph, \n","                batch_graph=batch_graph, \n","                epoch=0, #have no role in step() while testing \n","                K=5, \n","                J=8,\n","                weight=weight, \n","                norm=norm, \n","                dropout=0, \n","                optimizer=None, \n","                scheduler=None, \n","                device=device)\n","            #loss_accumulate += loss.detach().cpu().numpy()\n","           \n","            roc, avg_pre= get_auc(z_proc, adj, rk, decoder_type=\"bp\")\n","            if roc>max_test_auc:\n","              max_test_auc=roc\n","            if avg_pre>max_test_ap:\n","              max_test_ap=avg_pre\n","            #mse=get_mse(z_proc, adj, rk, decoder_type=\"bp\")\n","            rslt = \"Test ROC score: %f\" %(roc)\n","            rslt2=\"Test Precision score : %f\" %(avg_pre)\n","            #rslt=\"Test mean-squared error : %f\" %(mse)\n","            print(\"\\n\", rslt, \" \", rslt2, \"\\n\")\n","        # finalize fold\n","        torch.save(model.state_dict(), os.path.join(targetdir, 'model', str(k), 'model.pth'))\n","    '''\n","    wandb.finish()\n","    '''\n","    os.remove(os.path.join(targetdir, 'checkpoint.pth'))\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"bBvZeT9z0Gpj","outputId":"19a7d16c-35d2-4940-9d88-b39f8130efe8","executionInfo":{"status":"error","timestamp":1656493401727,"user_tz":-540,"elapsed":48814,"user":{"displayName":"김준엽","userId":"13244491849873010810"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/SIG-VAE-GIN-and-fMRI/SIG-VAE-GIN-and-fMRI/fMRI/HCP_REST1_LR_schaefer400_sub19.pth\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-22a1dfaa2ad6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mminibatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_ROI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_ROI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-419431cfbcca>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_epochs, target_feature, k_fold, dataset, targetdir, seed, quantile, learning_rate, num_ROI, graphbatch_size, minibatch_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# define dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'rest'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetHCPRest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matlas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'schaefer400_sub19'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'REST1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LR'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminibatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/SIG-VAE-GIN-and-fMRI/SIG-VAE-GIN-and-fMRI/Dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, atlas, target_feature, k_fold, session, phase_encoding)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# loading a cached timeseries files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeseries_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeseries_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeseries_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{prefix} {timeseries_file} is loaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m#print(self.timeseries_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    710\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     \u001b[0;31m# Load the data (which may in turn use `persistent_load` to load tensors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m     \u001b[0mdata_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#main\n","import warnings\n","if __name__=='__main__':\n","  warnings.filterwarnings(action='ignore')\n","\n","  num_epochs=10\n","  target_feature='Gender'\n","  k_fold=5\n","  dataset='rest'\n","  target_dir='/content/drive/MyDrive/SIG-VAE-GIN-and-fMRI/SIG-VAE-GIN-and-fMRI/experiments/BinaryFC'\n","  seed=5\n","  quantile=0.3\n","  learning_rate=0.0005\n","  num_ROI=419\n","  graphbatch_size=13\n","  minibatch_size=1\n","\n","  train(num_epochs, target_feature, k_fold, dataset, target_dir, seed, quantile, learning_rate, num_ROI, graphbatch_size, minibatch_size)\n","  print(\"train done!\")\n","  test(num_epochs, target_feature, k_fold, dataset, target_dir, seed, quantile, learning_rate, num_ROI, graphbatch_size, minibatch_size)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rav0llio9Ux3"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Unsupervied_HCP_binaryFC","provenance":[],"authorship_tag":"ABX9TyNBIwLZAFqytOfAhcwSJcw4"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}